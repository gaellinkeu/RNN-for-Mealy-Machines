{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# Accuracy ne prenant pas en compte les charactères complétés\n",
    "\n",
    "# Remove this when the cosineSimilarity will be added\n",
    "def cosineSimilarity(h1, h2):\n",
    "    return 2.3\n",
    "\n",
    "def ignore_class_accuracy(to_ignore=2):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy\n",
    "\n",
    "# Fonction qui imitte le comportement du réseau de neurone\n",
    "def get_hidden_state (word):\n",
    "    prec = 0.005\n",
    "    output = []\n",
    "    \n",
    "    for i, char in enumerate(word):\n",
    "        if char == \"a\":\n",
    "            prec = 0.02*(i+1) + prec\n",
    "            output.append(prec)\n",
    "        elif char == \"b\":\n",
    "            prec = 0.03*(i+1) + prec\n",
    "            output.append(prec)\n",
    "        elif char == \"e\":\n",
    "            prec = 0.005*(i+1) + prec\n",
    "            output.append(prec)\n",
    "        else:\n",
    "            prec = 0.05*(i+1) + prec\n",
    "            output.append(prec)\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_data(filepath):\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    #print(lines[:3])\n",
    "\n",
    "\n",
    "    #max_length = 0\n",
    "\n",
    "    for line in lines:\n",
    "        res = \"\"\n",
    "        isInput = True\n",
    "        for symbol in line:\n",
    "            if symbol in [',', '\\n']:\n",
    "                if isInput:\n",
    "                    inputs.append(res)\n",
    "                    #max_length = len(res) if len(res) > max_length else max_length\n",
    "                    res = \"\"\n",
    "                    isInput = not isInput\n",
    "                    continue\n",
    "                else:\n",
    "                    outputs.append(res)\n",
    "            res += symbol\n",
    "        #print(line)\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "def class_mapping(label, numb_class = 3):\n",
    "    y_train = []\n",
    "    for x in label:\n",
    "        assert int(x) < numb_class\n",
    "        y_train.append([int(i==int(x)) for i in range(numb_class)])\n",
    "        \n",
    "    return y_train\n",
    "\n",
    "def tokenization(word, num_token = 4):\n",
    "    x_train = []\n",
    "    for x in word:\n",
    "        if x == 'a':\n",
    "            x_train.append(1)\n",
    "        elif x == 'b':\n",
    "            x_train.append(2)\n",
    "        elif x == 'e':\n",
    "            x_train.append(3)\n",
    "        else:\n",
    "            x_train.append(0)\n",
    "    \n",
    "    return x_train\n",
    "\n",
    "def masking(word, pad_char = 'z'):\n",
    "    return [x!=pad_char for x in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Embedding\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def Tagger(n_tokens = 4, embedding_vector_length = 10, hidden_dim = 10, n_labels = 3, return_states = False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(n_tokens, embedding_vector_length))\n",
    "    model.add(SimpleRNN(hidden_dim, return_sequences=True))\n",
    "    if not return_states:\n",
    "        model.add(Dense(n_labels, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# These two functions work only for the specified configuration of the network\n",
    "\"\"\"def save_weights(model, filename):\n",
    "    weights = []\n",
    "    for layer in model.layers:\n",
    "        w = []\n",
    "        [w.append(x.tolist()) for x in layer.get_weights()]\n",
    "        weights.append(w)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(weights, f)\"\"\"\n",
    "\n",
    "def load_weights(model, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        weights = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "******************** ID 0:  TRAINING THE RECURRENT NEURAL NETWORK ********************\n",
      "\n",
      "\n",
      "\n",
      "The corpus is ['bba', 'abbabbbbba', 'aabaaba', 'bb', 'aa']\n",
      "The labels are ['111', '1011011111', '1001001', '11', '10']\n",
      "\n",
      "The length of corpus is: 800\n",
      "\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 3s 11ms/step - loss: 1.0313 - accuracy: 0.5796\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.8874 - accuracy: 0.7040\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7764 - accuracy: 0.7040\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6882 - accuracy: 0.7056\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6150 - accuracy: 0.7746\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4724 - accuracy: 0.8904\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.9312\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3357 - accuracy: 0.9592\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9778\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9845\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1940 - accuracy: 0.9870\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1638 - accuracy: 0.9874\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1396 - accuracy: 0.9908\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1201 - accuracy: 0.9950\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.9968\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9981\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.9989\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0698 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 1.0000\n",
      "\n",
      "\n",
      " The categorical crossentropy loss: 0.06182641535997391\n",
      "\n",
      "\n",
      " The accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "id = 0\n",
    "print('\\n\\n\\n'+'*'*20+f' ID {id}: '+' TRAINING THE RECURRENT NEURAL NETWORK '+'*'*20+'\\n\\n\\n')\n",
    "#max_length = 4\n",
    "#corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb']\n",
    "#labels = ['11', '1', '1', '110', '1', '1100', '10', '1', '1010', '101', '11']\n",
    "corpus, labels = get_data(f'./datasets/dataset{id}.txt')\n",
    "\n",
    "\n",
    "max_length = len(max(corpus, key=len))\n",
    "\n",
    "print(f'The corpus is {corpus[:5]}')\n",
    "print(f'The labels are {labels[:5]}')\n",
    "dev_percentage = 0.2\n",
    "dev_size = int(dev_percentage * len(corpus))\n",
    "dev_corpus = corpus[len(corpus) - dev_size:]\n",
    "dev_labels = labels[len(corpus) - dev_size:]\n",
    "dev_max_length = len(max(dev_corpus, key=len))\n",
    "\n",
    "corpus = corpus[:len(corpus) - dev_size]\n",
    "labels = labels[:len(labels) - dev_size]\n",
    "corpus_, labels_ = preprocessing(corpus, labels, max_length)\n",
    "dev_corpus_, dev_labels_ = preprocessing(dev_corpus, dev_labels, dev_max_length)\n",
    "\n",
    "dev_mask = [masking(x) for x in dev_corpus_]\n",
    "\n",
    "\"\"\"corpus_ = [\"e\"+x+\"z\"*(max_length - len(x)) for x in corpus]\n",
    "labels_ = [\"0\"+x+\"2\"*(max_length - len(x)) for x in labels]\"\"\"\n",
    "states = []\n",
    "print(f'\\nThe length of corpus is: {len(corpus)}\\n')\n",
    "\n",
    "x_train = np.array([tokenization(x) for x in corpus_])\n",
    "y_train = np.array([class_mapping(x) for x in labels_])\n",
    "\n",
    "x_test = np.array([tokenization(x) for x in dev_corpus_])\n",
    "y_test = np.array([class_mapping(x) for x in dev_labels_])\n",
    "\n",
    "mask = np.array([masking(x) for x in corpus_])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"version_name = '01'\n",
    "model_dir = os.path.join(\"weigths\", version_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "filepath = \"weigths/model_weights.h5\\\"\"\"\"\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "batch_size = 50\n",
    "n_epochs = 20\n",
    "\n",
    "model = Tagger(4, 10, 10, 3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size, n_epochs)\n",
    "# bacth de taille 2\n",
    "\n",
    "loss = history.history['loss'][-1]\n",
    "accuracy = history.history['accuracy'][-1]\n",
    "#print('\\n\\n\\n Les prédictions sont: \\n\\n')\n",
    "#print(train_preds)\n",
    "\n",
    "print(f'\\n\\n The categorical crossentropy loss: {loss}')\n",
    "print(f'\\n\\n The accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 1 3 3 3 3 3 3 3 3 3]\n",
      " [2 0 1 1 0 0 1 0 3 3 3 3]\n",
      " [2 1 1 0 1 1 0 0 3 3 3 3]\n",
      " [2 1 1 1 3 3 3 3 3 3 3 3]\n",
      " [2 0 0 0 0 0 0 0 0 3 3 3]]\n",
      "[[[1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(list_, mask):\n",
    "    string = ''\n",
    "    for i, x in enumerate(list_):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if mask[i]:\n",
    "            string += f'{x}'\n",
    "    return string\n",
    "\n",
    "def nparray_to_string(predictions, mask):\n",
    "    preds = predictions.tolist()\n",
    "    labels = []\n",
    "    for i, x in enumerate(preds):\n",
    "        labels.append(list_to_string(x, mask[i]))\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dev_corpus_:\n",
    "    if len(i) != 12:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dev_mask:\n",
    "    if len(i) != 12:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gael\\AppData\\Local\\Temp\\ipykernel_8976\\3189468442.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(np.asarray(dev_mask).shape)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(dev_mask).shape)\n",
    "print(predictions.argmax(axis=-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['10', '1011001', '1110110', '111', '10000000']\n",
      "['10', '1011001', '1110110', '111', '10000000']\n",
      "['10', '1011001', '1110110', '111', '10000000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = predictions.argmax(axis=-1)\n",
    "#label = y.join()\n",
    "x = y.tolist()\n",
    "#print(y.shape)\n",
    "print(x[0])\n",
    "#print(y_test.argmax(axis=-1))\n",
    "#final_label = [idx_to_label[i] for i in y.detach().cpu().numpy()]\n",
    "#print(final_label)\n",
    "#predictions[:5]\n",
    "uy = nparray_to_string(y, dev_mask)\n",
    "print(uy[:5])\n",
    "print(nparray_to_string(y_test[:5].argmax(axis=-1), dev_mask[:5]))\n",
    "print(dev_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3788919903.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[63], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    assert(2 == 2) 'Ce nest pas '\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "assert(2 == 2) 'Ce nest pas '\n",
    "rr = [2, 3,4]\n",
    "rr.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type if scores is [0.07397884130477905, 1.0]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Type if scores is {scores}\")\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m labels \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor([[[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],\n\u001b[0;32m      4\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m]],\n\u001b[0;32m      5\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],\n\u001b[0;32m      6\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],\n\u001b[0;32m      7\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]]])\n\u001b[1;32m----> 9\u001b[0m logits \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor([[[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]],\n\u001b[0;32m     10\u001b[0m                                 [[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m]],\n\u001b[0;32m     11\u001b[0m                                 [[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]],\n\u001b[0;32m     12\u001b[0m                                 [[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]],\n\u001b[0;32m     13\u001b[0m                                 [[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]]])\n\u001b[0;32m     15\u001b[0m bool_acc \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mequal(tf\u001b[39m.\u001b[39margmax(logits, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), tf\u001b[39m.\u001b[39margmax(labels, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     16\u001b[0m accuracy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mcast(bool_acc, tf\u001b[39m.\u001b[39mfloat32))\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "labels = tf.convert_to_tensor([[[1,0,0],[1,0,0],[0,0,1]],\n",
    "                                [[0,1,0],[1,0,0],[0,1,0]],\n",
    "                                [[0,0,1],[0,0,1],[0,0,1]],\n",
    "                                [[0,1,0],[1,0,0],[0,0,1]],\n",
    "                                [[0,0,1],[0,1,0],[0,0,1]]])\n",
    "\n",
    "logits = tf.convert_to_tensor([[[0.1,0.9,0],[0.1,9,0,0],[0,0.1,0.9]],\n",
    "                                [[0.1,0.9,0],[0.1,9,0,0],[0.1,0.9,0]],\n",
    "                                [[0,0.1,0.9],[0,0.1,0.9],[0,0.1,0.9]],\n",
    "                                [[0.1,0.9,0],[0.1,9,0,0],[0,0.1,0.9]],\n",
    "                                [[0,0.1,0.9],[0.1,0.9,0],[0,0.1,0.9]]])\n",
    "\n",
    "bool_acc = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "accuracy = tf.reduce_mean(tf.cast(bool_acc, tf.float32))\n",
    "\n",
    "print(accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baby come over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.3>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create an optimizer.\n",
    "opt = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n",
    "var1, var2 = tf.Variable(1.0), tf.Variable(2.0)\n",
    "\n",
    "# Compute the gradients for a list of variables.\n",
    "with tf.GradientTape() as tape:\n",
    "  loss = 3 * var1 * var1 + 2 * var2 * var2\n",
    "grads = tape.gradient(loss, [var1, var2])\n",
    "\n",
    "# Process the gradients.\n",
    "grads[0] = grads[0] + 1\n",
    "\n",
    "# Ask the optimizer to apply the gradients on variables.\n",
    "opt.apply_gradients(zip(grads, [var1, var2]))\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_prefix(mealy, dataset, labels):\n",
    "    # A bunch of code on how to determine if a label correctly corresponds\n",
    "    # to the output of the mealy machine\n",
    "    scores = 0\n",
    "    total = 0\n",
    "    for i in range(len(dataset)):\n",
    "        output = mealy.return_output(dataset[i])\n",
    "        print(output)\n",
    "        score = [labels[i][j] == output[j] for j in range(len(output))]\n",
    "        scores += score.count(True)\n",
    "        total += len(output)\n",
    "\n",
    "    return scores/total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 'a', '0', 3], [1, 'b', '0', 3], [0, 'b', '0', 3]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "a = ['eaaab', 'ebabb', 'eaac', 'eaab']\n",
    "b = ['00001', '01011', '0001', '0010']\n",
    "arcs = [[2,'a', '0', 3],[1,'b', '0', 3],[2,'a', '0', 3],[0,'b', '0', 3],[1,'b', '0', 3],]\n",
    "\n",
    "class Mealy(object):\n",
    "\n",
    "    def __init__(self, id, root, nodes, arcs):\n",
    "        # nodes = [0,1,2,...]\n",
    "        # arcs = [(0,a,1,1), ...]\n",
    "        self.id = id\n",
    "        self.root =  root\n",
    "        self.nodes = nodes\n",
    "        self.transitions = [list(x) for x in arcs]\n",
    "        self.inputAlphabet = []\n",
    "        self.outputAlphabet = []\n",
    "\n",
    "        for x in self.transitions:\n",
    "            if x[1] not in self.inputAlphabet:\n",
    "                self.inputAlphabet.append(x[1])\n",
    "            if x[2] not in self.outputAlphabet:\n",
    "                self.outputAlphabet.append(x[2])\n",
    "    \n",
    "    def output(self, initial_state, input_char):\n",
    "        for x in self.transitions:\n",
    "            if x[0] == initial_state and x[1] ==  input_char:\n",
    "                return (x[2], x[3])\n",
    "        return None\n",
    "\n",
    "    def getInpOut(self, node):\n",
    "        inp_out = []\n",
    "        for x in self.transitions:\n",
    "            if x[0] == node:\n",
    "                inp_out.append([x[1],x[2]])\n",
    "        \n",
    "        return inp_out\n",
    "\n",
    "    # get the output of the machine given a word\n",
    "    def return_output(self, word):\n",
    "        # we consider that the word comes without the bos sign\n",
    "        output = ''\n",
    "        idx = self.root\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx, word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx} with {word[i]}')\n",
    "            break\n",
    "           output += self.output(idx, word[i])[0]\n",
    "           idx = self.output(idx, word[i])[1]\n",
    "        return output\n",
    "    \n",
    "    # get the trace of the machine given a word\n",
    "    def return_states(self, word):\n",
    "        \n",
    "        # we consider that the word comes without the bos sign\n",
    "        # for a word abba we have [0,1,2,3,4] for example\n",
    "        idx = [self.root]\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx[i], word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx[i]} with {word[i]}')\n",
    "            break\n",
    "           idx.append(self.output(idx[i], word[i])[1])\n",
    "        return idx\n",
    "    \n",
    "    \n",
    "    \n",
    "    def print(self):\n",
    "        print(f'\\nThe amount of states is {len(self.nodes)}')\n",
    "        #print(\"Different states of the Tree: \")\n",
    "        #for i in self.nodes:\n",
    "        #    print(f'ID: {i}\\tHidden value: {0}')\n",
    "\n",
    "        print(f'The amount of Transitions is {len(self.transitions)}')\n",
    "        print(f\"\\nFirst {len(self.transitions)} Transitions of the FSM\")\n",
    "        if len(self.transitions) <= 10 :\n",
    "            for transition in self.transitions:\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "        else:\n",
    "            for i, transition in enumerate(self.transitions):\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "                if i == 9:\n",
    "                    break\n",
    "\n",
    "states = [1,2,3]\n",
    "arcs = [(0, 'a', '0', 0),\n",
    "        (0, 'b', '1', 1),\n",
    "        (1, 'a', '1', 1),\n",
    "        (1, 'b', '0', 2),\n",
    "        (2, 'b', '0', 0),\n",
    "        (2, 'a', '1', 1)]\n",
    "\n",
    "m = Mealy(0, 0, states, arcs)\n",
    "print(m.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb', 'abb', 'aaaa', 'baaaaab', 'abababb']\n",
    "_labels = ['11', '1', '0', '111', '0', '1111', '00', '1', '0111', '010', '10', '011', '0000', '1111110', '0110100']\n",
    "def score_whole_words(mealy, dataset, labels):\n",
    "    acc = 0\n",
    "    for word, y in zip(dataset, labels):\n",
    "        acc += (mealy.return_output(word) == y)\n",
    "    return (acc / len(dataset) * 100)\n",
    "\n",
    "_acc = score_whole_words(m, _corpus, _labels)\n",
    "_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of states is 11\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 1\n",
      "1 --> a/1 --> 2\n",
      "2 --> a/0 --> 4\n",
      "4 --> a/0 --> 5\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 7\n",
      "7 --> b/1 --> 10\n",
      "7 --> a/1 --> 8\n",
      "8 --> a/0 --> 9\n",
      "3 --> a/0 --> 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "class Mealy(object):\n",
    "\n",
    "    def __init__(self, id, root, nodes, arcs):\n",
    "        # nodes = [0,1,2,...]\n",
    "        # arcs = [(0,a,1,1), ...]\n",
    "        self.id = id\n",
    "        self.root =  root\n",
    "        self.nodes = nodes\n",
    "        self.transitions = [list(x) for x in arcs]\n",
    "        self.inputAlphabet = []\n",
    "        self.outputAlphabet = []\n",
    "\n",
    "        for x in self.transitions:\n",
    "            if x[1] not in self.inputAlphabet:\n",
    "                self.inputAlphabet.append(x[1])\n",
    "            if x[2] not in self.outputAlphabet:\n",
    "                self.outputAlphabet.append(x[2])\n",
    "    \n",
    "    def output(self, initial_state, input_char):\n",
    "        for x in self.transitions:\n",
    "            if x[0] == initial_state and x[1] ==  input_char:\n",
    "                return (x[2], x[3])\n",
    "        return None\n",
    "\n",
    "    def getInpOut(self, node):\n",
    "        inp_out = []\n",
    "        for x in self.transitions:\n",
    "            if x[0] == node:\n",
    "                inp_out.append([x[1],x[2]])\n",
    "        \n",
    "        return inp_out\n",
    "\n",
    "    # get the output of the machine given a word\n",
    "    def return_output(self, word):\n",
    "        # we consider that the word comes without the bos sign\n",
    "        output = ''\n",
    "        idx = self.root\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx, word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx} with {word[i]}')\n",
    "            break\n",
    "           output += self.output(idx, word[i])[0]\n",
    "           idx = self.output(idx, word[i])[1]\n",
    "        return output\n",
    "    \n",
    "    # get the trace of the machine given a word\n",
    "    def return_states(self, word):\n",
    "        \n",
    "        # we consider that the word comes without the bos sign\n",
    "        # for a word abba we have [0,1,2,3,4] for example\n",
    "        idx = [self.root]\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx[i], word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx[i]} with {word[i]}')\n",
    "            break\n",
    "           idx.append(self.output(idx[i], word[i])[1])\n",
    "        return idx\n",
    "    \n",
    "    \n",
    "    \n",
    "    def print(self):\n",
    "        print(f'\\nThe amount of states is {len(self.nodes)}')\n",
    "        #print(\"Different states of the Tree: \")\n",
    "        #for i in self.nodes:\n",
    "        #    print(f'ID: {i}\\tHidden value: {0}')\n",
    "\n",
    "        print(f'The amount of Transitions is {len(self.transitions)}')\n",
    "        print(f\"\\nFirst {len(self.transitions)} Transitions of the FSM\")\n",
    "        if len(self.transitions) <= 10 :\n",
    "            for transition in self.transitions:\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "        else:\n",
    "            for i, transition in enumerate(self.transitions):\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "                if i == 9:\n",
    "                    break\n",
    "\n",
    "    def removeDuplicate(self):\n",
    "        add = True\n",
    "        states = []\n",
    "        for x in self.nodes:\n",
    "            if x not in states:\n",
    "                states.append(x)\n",
    "        \n",
    "        self.nodes = deepcopy(states)\n",
    "\n",
    "        transitions = [self.transitions[0]]\n",
    "        for x in self.transitions:\n",
    "            for y in transitions:\n",
    "                if x == y:\n",
    "                    add = False\n",
    "            if add:\n",
    "                transitions.append(x)\n",
    "            add = True\n",
    "        self.transitions = deepcopy(transitions)\n",
    "\n",
    "        nodes = []\n",
    "        for x in self.transitions:\n",
    "            if x[0] not in nodes:\n",
    "                nodes.append(x[0])\n",
    "            if x[3] not in nodes:\n",
    "                nodes.append(x[3])\n",
    "\n",
    "        self.nodes = deepcopy(nodes)\n",
    "        \n",
    "        \n",
    "    def merge_states(self, state1, state2):\n",
    "        \n",
    "\n",
    "        self.merging(state1, state2)\n",
    "        \n",
    "        #self.removeDuplicate()\n",
    "        self.print()\n",
    "\n",
    "\n",
    "    def merging(self, state1, state2):\n",
    "        print(f'\\n The two states are {state1} and {state2}\\n')\n",
    "        submerged = False\n",
    "        if state1 == state2:\n",
    "            return 0\n",
    "        if (state1 not in self.nodes or state2 not in self.nodes):\n",
    "            return 1\n",
    "        \n",
    "        for i in range(len(self.transitions)):\n",
    "            for j in range(len(self.transitions)):\n",
    "                if(i == j):\n",
    "                    continue\n",
    "\n",
    "                # merge the children of the two mergable states\n",
    "                if self.transitions[i][0] == state1 and self.transitions[j][0] == state2:\n",
    "                    if self.transitions[i][1:3] == self.transitions[j][1:3]:\n",
    "                        submerged = True\n",
    "                        print(f'\\n The two SUB states are {self.transitions[i][3]} and {self.transitions[j][3]}\\n')\n",
    "                        self.merging(self.transitions[i][3], self.transitions[j][3])\n",
    "\n",
    "        for i in range(len(self.transitions)):\n",
    "            if self.transitions[i][0] == state2:\n",
    "                self.transitions[i][0] = state1\n",
    "            if self.transitions[i][3] == state2:\n",
    "                self.transitions[i][3] = state1\n",
    "        \n",
    "        # If the merged is the root\n",
    "        if self.root == state2:\n",
    "            self.root = state1\n",
    "\n",
    "        # Delete the merged state\n",
    "        \"\"\"if state2 in self.nodes:\n",
    "            self.nodes.remove(state2)\"\"\"\n",
    "\n",
    "        # Remove doble transaction\n",
    "        transitions = []\n",
    "\n",
    "        \"\"\"for x in self.transitions:\n",
    "            add = True\n",
    "            for y in transitions:\n",
    "                if x == y:\n",
    "                    add = False\n",
    "            if add:\n",
    "                transitions.append(x)\n",
    "            \n",
    "        self.transitions = deepcopy(transitions)\"\"\"\n",
    "        #print(self.transitions)\n",
    "        \n",
    "        \n",
    "        #self.print()\n",
    "\n",
    "        return 0\n",
    "\n",
    "nodes = [0,1,2]\n",
    "arcs = [(0,'b','1',1),\n",
    "        (0,'a','0',0),\n",
    "        (1,'a','1',1),\n",
    "        (1,'b','0',2),\n",
    "        (2,'a','1',1),\n",
    "        (2,'b','0',0)]\n",
    "\n",
    "fsm = Mealy(0, 0, nodes, arcs)\n",
    "fsm.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 7, 10]\n",
      "101\n",
      "There's no transitions from 1 with b\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(fsm.return_states('abb'))\n",
    "print(fsm.return_output('abb'))\n",
    "print(fsm.return_states('bbb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The two states are 0 and 1\n",
      "\n",
      "The amount of states is 11\n",
      "\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 7\n",
      "7 --> b/1 --> 10\n",
      "7 --> a/1 --> 8\n",
      "8 --> a/0 --> 9\n",
      "3 --> a/0 --> 3\n",
      "\n",
      " The two states are 3 and 6\n",
      "\n",
      "The amount of states is 11\n",
      "\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 7\n",
      "7 --> b/1 --> 10\n",
      "7 --> a/1 --> 8\n",
      "8 --> a/0 --> 9\n",
      "3 --> a/0 --> 3\n",
      "\n",
      " The two states are 0 and 7\n",
      "\n",
      "\n",
      " The two SUB states are 0 and 10\n",
      "\n",
      "\n",
      " The two states are 0 and 10\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 8\n",
      "\n",
      "\n",
      " The two states are 3 and 8\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 9\n",
      "\n",
      "\n",
      " The two states are 3 and 9\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 3\n",
      "\n",
      "\n",
      " The two states are 3 and 3\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 3\n",
      "\n",
      "\n",
      " The two states are 3 and 3\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 3\n",
      "\n",
      "\n",
      " The two states are 3 and 3\n",
      "\n",
      "The amount of states is 11\n",
      "\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 0\n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n"
     ]
    }
   ],
   "source": [
    "#fsm.merge_states(2,4)\n",
    "#fsm.merge_states(0,1)\n",
    "#fsm.merge_states(3,6)\n",
    "#fsm.merge_states(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(states)):\n\u001b[0;32m     62\u001b[0m         sim1[i]\u001b[39m.\u001b[39mappend(cosine(states[i], states[j]))\n\u001b[1;32m---> 64\u001b[0m sim1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(sim1)\n\u001b[0;32m     65\u001b[0m \u001b[39m#print(sim1)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m fusionable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine(h1, h2):\n",
    "    cos = 0\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    assert len(h1) == len(h2)\n",
    "    for i in range(len(h1)):\n",
    "        cos += h1[i]*h2[i]\n",
    "        s1 += h1[i]**2\n",
    "        s2 += h2[i]**2\n",
    "    s1 = s1**(1/2)\n",
    "    s2 = s2**(1/2)\n",
    "    return cos/(s1*s2)\n",
    "\n",
    "\n",
    "mask = [[True, True, True, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, True, True, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, False, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, True, False]]\n",
    "labels  = np.array([[0,1,1,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,1,0,2],\n",
    "        [0,1,1,0,0],\n",
    "        [0,1,0,2,2],\n",
    "        [0,1,0,1,0],\n",
    "        [0,1,0,1,2]])\n",
    "representations = np.array([[[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.3, 4.5], [2.67, 1.01]]])\n",
    "idx = [[0,1,2], \n",
    "    [0,1],\n",
    "    [0,3],\n",
    "    [0,1,2,4],\n",
    "    [0,1,2,4,5],\n",
    "    [0,3,6],\n",
    "    [0,3,7,8,9],\n",
    "    [0,3,7,10]] # maps strings to states\n",
    "n_states = 11\n",
    "states = np.zeros((n_states, 2))\n",
    "states_mask = np.zeros(n_states)\n",
    "\n",
    "for i, _r in enumerate(representations):\n",
    "    #print(_r)\n",
    "    states[idx[i]] = _r[mask[i]]\n",
    "    states_mask[idx[i]] = labels[i][mask[i]]\n",
    "\n",
    "sim1 = []\n",
    "for i in range(len(states)):\n",
    "    sim1.append([])\n",
    "    for j in range(len(states)):\n",
    "        sim1[i].append(cosine(states[i], states[j]))\n",
    "\n",
    "sim1 = tf.convert_to_tensor(sim1)\n",
    "#print(sim1)\n",
    "\n",
    "fusionable = True\n",
    "res, pruned = 0, 0\n",
    "threshold = 1\n",
    "total = 0\n",
    "ter = 0\n",
    "\n",
    "\"\"\"while fusionable and ter < 10:\n",
    "    fusionable = False\n",
    "    ter += 1\"\"\"\n",
    "\n",
    "#fsm.print()\n",
    "\n",
    "\"\"\"for i in range(states.shape[0]):\n",
    "    for j in range(i):\n",
    "        pass_ = False\n",
    "        if(i == j):\n",
    "            continue\n",
    "        for x in fsm.getInpOut(i):\n",
    "            for y in fsm.getInpOut(j):\n",
    "                if(x[0] == y[0] and x[1] != y[1]):\n",
    "                    pass_ = True\n",
    "        #print(f'--we have {i} and {j} and the similarity {sim[i][j]}')\n",
    "        if pass_:\n",
    "            continue\n",
    "        \n",
    "        if(sim1[i][j] >= threshold):\n",
    "            print(f'The states to merge {i} and {j}')\n",
    "            fusionable = True\n",
    "            total += 1\n",
    "            res = fsm.merge_states(i, j)\n",
    "            #pruned += 1 - res\"\"\"\n",
    "    \n",
    "\n",
    "#print(states)\n",
    "#print(states_mask)\n",
    "#print(sim[0])\n",
    "#fsm.print()\n",
    "#fsm.removeDuplicate()\n",
    "#print('After Duplicate deletion')\n",
    "#fsm.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_merging(fsm, states, states_mask, threshold = 1.0):\n",
    "\n",
    "    cos = tf.keras.losses.CosineSimilarity(axis=-1)\n",
    "    sim = -cos(states[None, :, :], states[:, None, :])\n",
    "     \n",
    "    total, pruned = 0, 0\n",
    "    fsm_ = deepcopy(fsm)\n",
    "\n",
    "    for i in range(states.shape[0]):\n",
    "        for j in range(i):\n",
    "            pass_ = False\n",
    "            if(i == j):\n",
    "                continue\n",
    "            for x in fsm_.getInpOut(i):\n",
    "                for y in fsm_.getInpOut(j):\n",
    "                    if(x[0] == y[0] and x[1] != y[1]):\n",
    "                        pass_ = True\n",
    "            #print(f'--we have {i} and {j} and the similarity {sim[i][j]}')\n",
    "            if pass_:\n",
    "                continue\n",
    "            \n",
    "            if(sim[i][j] >= threshold):\n",
    "                print(f'The states to merge {i} and {j}')\n",
    "                fusionable = True\n",
    "                total += 1\n",
    "                res = fsm_.merge_states(i, j)\n",
    "                #pruned += 1 - res\n",
    "                \n",
    "    fsm_.removeDuplicate()\n",
    "    fsm_.print()\n",
    "    fsm_.id = str(fsm_.id) + 'min'\n",
    "    return fsm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 0; input has only 0 dims [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 46\u001b[0m\n\u001b[0;32m     41\u001b[0m     states_mask[idx[i]] \u001b[39m=\u001b[39m labels[i][mask[i]]\n\u001b[0;32m     43\u001b[0m \u001b[39m#cos = tf.keras.losses.CosineSimilarity(axis=-1,reduction=tf.keras.losses.Reduction.NONE)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m#sim = -cos(states[None, :, :], states[:, None, :])\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m merged_fsm \u001b[39m=\u001b[39m cosine_merging(fsm, states, states_mask)\n",
      "Cell \u001b[1;32mIn[39], line 22\u001b[0m, in \u001b[0;36mcosine_merging\u001b[1;34m(fsm, states, states_mask, threshold)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m pass_:\n\u001b[0;32m     20\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mif\u001b[39;00m(sim[i][j] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold):\n\u001b[0;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe states to merge \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m     fusionable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 0; input has only 0 dims [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "mask = [[True, True, True, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, True, True, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, False, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, True, False]]\n",
    "labels  = np.array([[0,1,1,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,1,0,2],\n",
    "        [0,1,1,0,0],\n",
    "        [0,1,0,2,2],\n",
    "        [0,1,0,1,0],\n",
    "        [0,1,0,1,2]])\n",
    "representations = np.array([[[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.3, 4.5], [2.67, 1.01]]])\n",
    "idx = [[0,1,2], \n",
    "    [0,1],\n",
    "    [0,3],\n",
    "    [0,1,2,4],\n",
    "    [0,1,2,4,5],\n",
    "    [0,3,6],\n",
    "    [0,3,7,8,9],\n",
    "    [0,3,7,10]] # maps strings to states\n",
    "n_states = 11\n",
    "states = np.zeros((n_states, 2))\n",
    "states_mask = np.zeros(n_states)\n",
    "\n",
    "for i, _r in enumerate(representations):\n",
    "    #print(_r)\n",
    "    states[idx[i]] = _r[mask[i]]\n",
    "    states_mask[idx[i]] = labels[i][mask[i]]\n",
    "\n",
    "#cos = tf.keras.losses.CosineSimilarity(axis=-1,reduction=tf.keras.losses.Reduction.NONE)\n",
    "#sim = -cos(states[None, :, :], states[:, None, :])\n",
    "\n",
    "merged_fsm = cosine_merging(fsm, states, states_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'110'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_fsm.return_output('bab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb', 'abb', 'aaaa', 'baaaaab', 'abababb']\n",
    "_labels = ['11', '1', '0', '111', '0', '1111', '00', '1', '0111', '010', '10', '011', '0000', '1111110', '0110100']\n",
    "def score_whole_words(mealy, dataset, labels):\n",
    "    acc = 0\n",
    "    for word, y in zip(dataset, labels):\n",
    "        acc += (mealy.return_output(word) == y)\n",
    "    return (acc / len(dataset) * 100)\n",
    "\n",
    "_acc = score_whole_words(merged_fsm, _corpus, _labels)\n",
    "_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11, 11), dtype=float64, numpy=\n",
       "array([[1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 1e-12 to EagerTensor of dtype int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m], [\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m]])\n\u001b[0;32m      2\u001b[0m b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m2.1\u001b[39m, \u001b[39m3.2\u001b[39m], [\u001b[39m4.8\u001b[39m, \u001b[39m5.7\u001b[39m]])\n\u001b[1;32m----> 3\u001b[0m sim \u001b[39m=\u001b[39m cos(a[\u001b[39mNone\u001b[39;49;00m, :, :], a[:, \u001b[39mNone\u001b[39;49;00m, :])\n\u001b[0;32m      4\u001b[0m sim\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py:142\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    139\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 142\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[0;32m    144\u001b[0m in_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(y_pred)\n\u001b[0;32m    145\u001b[0m out_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(losses)\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py:268\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    261\u001b[0m     y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    262\u001b[0m         y_pred, y_true\n\u001b[0;32m    263\u001b[0m     )\n\u001b[0;32m    265\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    267\u001b[0m )\n\u001b[1;32m--> 268\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py:2461\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(y_true, y_pred, axis)\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[39m@keras_export\u001b[39m(\n\u001b[0;32m   2421\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkeras.losses.cosine_similarity\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2422\u001b[0m     v1\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcosine_similarity\u001b[39m(y_true, y_pred, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   2432\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Computes the cosine similarity between labels and predictions.\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \n\u001b[0;32m   2434\u001b[0m \u001b[39m    Note that it is a number between -1 and 1. When it is a negative number\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2459\u001b[0m \u001b[39m      Cosine similarity tensor.\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2461\u001b[0m     y_true \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49ml2_normalize(y_true, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   2462\u001b[0m     y_pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39ml2_normalize(y_pred, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   2463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mtf\u001b[39m.\u001b[39mreduce_sum(y_true \u001b[39m*\u001b[39m y_pred, axis\u001b[39m=\u001b[39maxis)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert 1e-12 to EagerTensor of dtype int32"
     ]
    }
   ],
   "source": [
    "a = np.array([[2,3], [5,6]])\n",
    "b = np.array([[2.1, 3.2], [4.8, 5.7]])\n",
    "sim2 = cos(a[None, :, :], a[:, None, :])\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rer = [['a','0'],['b','1']]\n",
    "rerr = []\n",
    "sas = []\n",
    "if all(x in rer for x in rerr):\n",
    "    print(True)\n",
    "#rer = [set(x) for x in rer]\n",
    "#rerr = [set(x) for x in rerr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from mealy_machine import Mealy\n",
    "def fsm_equivalence(fsm1 : Mealy, fsm2 : Mealy):\n",
    "    if set(fsm1.inputAlphabet) != set(fsm2.inputAlphabet):\n",
    "        print('The two FSM don\\'t have the same input set' )\n",
    "        return 0\n",
    "    if set(fsm1.outputAlphabet) != set(fsm2.outputAlphabet):\n",
    "        print('The two FSM don\\'t have the same output set' )\n",
    "        return 0\n",
    "    start = (fsm1.root, fsm2.root)\n",
    "    inputAlphabet = set(fsm1.inputAlphabet + fsm2.inputAlphabet)\n",
    "    outputAlphabet = set(fsm1.outputAlphabet + fsm2.outputAlphabet)\n",
    "    nodes = [start]\n",
    "    nodes_ = deepcopy(nodes)\n",
    "    print('Starting')\n",
    "    print(nodes[0])\n",
    "    while len(nodes) != 0:\n",
    "        node = nodes[0]\n",
    "        for x in inputAlphabet:\n",
    "            output1 = fsm1.output(node[0], x)\n",
    "            output2 = fsm2.output(node[1], x)\n",
    "            #print(f'The len is {len(nodes)}')\n",
    "            #print(f'{node}   {x}   {(output1[1],output2[1])}')\n",
    "            if output1[0] != output2[0]:\n",
    "                return 0\n",
    "            \n",
    "            #print((output1[1], output2[1]))\n",
    "            node_ = (output1[1], output2[1])\n",
    "            if node_ not in nodes_:\n",
    "                nodes_.append(node_)\n",
    "                nodes.append(node_)\n",
    "        \n",
    "        nodes.pop(0)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "(0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mealy_machine import Mealy\n",
    "nodes1 = [0, 1, 2, 4]\n",
    "nodes2 = [0, 1]\n",
    "\n",
    "arcs1 = [(0,'b','1',1),\n",
    "         (1,'a','1',2),\n",
    "         (2,'a','0',4),\n",
    "         (4,'a','0',4),\n",
    "         (4,'b','0',0),\n",
    "         (1,'b','1',1),\n",
    "         (0,'a','1',2),\n",
    "         (2,'b','0',0)]\n",
    "arcs2 = [(0,'b','1',0),\n",
    "         (0,'a','1',1),\n",
    "         (1,'a','0',1),\n",
    "         (1,'b','0',0)]\n",
    "fsm1 = Mealy(0, 0, nodes1, arcs1)\n",
    "fsm2 = Mealy(1, 0, nodes2, arcs2)\n",
    "fsm_equivalence(fsm1, fsm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "rere = [5,8,9,6]\n",
    "for i in rere:\n",
    "    if i < 2:\n",
    "        break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus, labels, max_length):\n",
    "    \n",
    "    bos = ['e', 'f', 'g']  # Plausible beginning of sentence marker\n",
    "    for b in bos:\n",
    "        if b not in set(corpus):\n",
    "            break\n",
    "\n",
    "    eos = ['z', 'y', 'x'] # Plausible end of sentence marker\n",
    "    \n",
    "    for e in eos:\n",
    "        if e not in set(corpus):\n",
    "            break\n",
    "    pad_label = ['0', '1', '2', '3', '4']  \n",
    "\n",
    "    corpus_ = [b+x+e*(max_length-len(x)) for x in corpus]\n",
    "\n",
    "    for p in pad_label:\n",
    "        if p not in set(corpus):\n",
    "            break\n",
    "    labels_ = ['0'+x+p*(max_length-len(x)) for x in labels]\n",
    "    return corpus_, labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ebazzzzz', 'ebzzzzzz', 'eazzzzzz', 'ebaazzzz', 'eazzzzzz', 'ebaaazzz', 'eaazzzzz', 'ebzzzzzz', 'eabaazzz', 'eabbzzzz', 'ebbzzzzz', 'eabbzzzz', 'eaaaazzz', 'ebaaaaab', 'eabababa']\n",
      "['01100000', '01000000', '01000000', '01100000', '01000000', '01100000', '01000000', '01000000', '01010000', '01010000', '01100000', '01010000', '01000000', '01100000', '01010101']\n"
     ]
    }
   ],
   "source": [
    "corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb', 'abb', 'aaaa', 'baaaaab', 'abababa']\n",
    "labels = ['11', '1', '1', '110', '1', '1100', '10', '1', '1010', '101', '11', '101', '1000', '1100000', '1010101']\n",
    "assert(len(corpus) == len(labels))\n",
    "max_length = len(max(corpus, key=len))\n",
    "corpus_, labels_ = preprocessing(corpus, labels, max_length)\n",
    "print(corpus_)\n",
    "print(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbaabbbabb',\n",
       " 'ba',\n",
       " 'baaaa',\n",
       " 'bbbbabbbbbb',\n",
       " 'babbbbabaaba',\n",
       " 'aabaabbbabbab',\n",
       " 'aaabab',\n",
       " 'babababaaa',\n",
       " 'babababbabbaaa',\n",
       " 'aaaabbabbbbaba',\n",
       " 'aababa',\n",
       " 'abb',\n",
       " 'b',\n",
       " 'baabaabaa',\n",
       " 'baabaabb',\n",
       " 'aaaba',\n",
       " 'ab',\n",
       " 'aababbbbbaa',\n",
       " 'abaaaababababb',\n",
       " 'aaaaabaababaaa',\n",
       " 'bbabbbbabb',\n",
       " 'abbbb',\n",
       " 'b',\n",
       " 'abbabbba',\n",
       " 'b',\n",
       " 'babbaabbbba',\n",
       " 'bababbaabbbb',\n",
       " 'abaa',\n",
       " 'abbaaabb',\n",
       " 'aabbbababb',\n",
       " 'aaabbaabbb',\n",
       " 'aabbabba',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'bbbbabababbbaa',\n",
       " 'bbabbababbabb',\n",
       " 'bbbb',\n",
       " 'abaaabbabbabb',\n",
       " 'baaabb',\n",
       " 'abab',\n",
       " 'bbbbababaaabb',\n",
       " 'abbabab',\n",
       " 'bbaababa',\n",
       " 'bbabbbab',\n",
       " 'abbbbab',\n",
       " 'abbbabaa',\n",
       " 'abababaaaaaaa',\n",
       " 'bbbbbaabaaba',\n",
       " 'abbbbaabbbab',\n",
       " 'abaaabbabbab',\n",
       " 'bbaab',\n",
       " 'baaaaa',\n",
       " 'babbababbbab',\n",
       " 'baabbb',\n",
       " 'aaaa',\n",
       " 'abbbbb',\n",
       " 'ababbbaaaabbb',\n",
       " 'aaaaaaaa',\n",
       " 'ab',\n",
       " 'bba',\n",
       " 'bbbbbaabbb',\n",
       " 'abaab',\n",
       " 'bba',\n",
       " 'babbaaaabaaaa',\n",
       " 'aaaaaabbbb',\n",
       " 'babbbbaaaaa',\n",
       " 'baa',\n",
       " 'baabbb',\n",
       " 'b',\n",
       " 'bbbbaababbaba',\n",
       " 'aaaaabbba',\n",
       " 'bbbaaaabab',\n",
       " 'abbbb',\n",
       " 'a',\n",
       " 'baaaaaaabb',\n",
       " 'aaaabbbaaaabba',\n",
       " 'aabababaaab',\n",
       " 'bababbab',\n",
       " 'babaaaa',\n",
       " 'bbabb',\n",
       " 'abbaab',\n",
       " 'bbb',\n",
       " 'babaaabbbaab',\n",
       " 'a',\n",
       " 'aaabbbaa',\n",
       " 'ababaaaabbabaa',\n",
       " 'aaaaabb',\n",
       " 'abababaab',\n",
       " 'bababbab',\n",
       " 'baaba',\n",
       " 'bbababbbbbbbba',\n",
       " 'abaaaa',\n",
       " 'abbbbb',\n",
       " 'bbabaaaababaaa',\n",
       " 'aabbbbaababa',\n",
       " 'aabaa',\n",
       " 'baabab',\n",
       " 'aaaababab',\n",
       " 'aaaaaba',\n",
       " 'aba',\n",
       " 'abbbbbbbaaab',\n",
       " 'bbabaa',\n",
       " 'babababbb',\n",
       " 'b',\n",
       " 'baaabbabb',\n",
       " 'aaabaaabaab',\n",
       " 'bbaabb',\n",
       " 'b',\n",
       " 'abaabaa',\n",
       " 'abaaa',\n",
       " 'aabbabb',\n",
       " 'bbaaba',\n",
       " 'bbbbbbab',\n",
       " 'babbb',\n",
       " 'baaababba',\n",
       " 'babaaababab',\n",
       " 'bababbabbbbaba',\n",
       " 'bbbabab',\n",
       " 'bb',\n",
       " 'baaaaabbba',\n",
       " 'abaabab',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'abbbbbaa',\n",
       " 'bbb',\n",
       " 'abbbbabbaa',\n",
       " 'bbbabbaaaa',\n",
       " 'baaaabba',\n",
       " 'abaaaaabab',\n",
       " 'abbbbababab',\n",
       " 'aaababab',\n",
       " 'aababbaa',\n",
       " 'bababbba',\n",
       " 'a',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'baaabbbababb',\n",
       " 'bbabbb',\n",
       " 'bbaababbaaa',\n",
       " 'aab',\n",
       " 'aaaaa',\n",
       " 'baa',\n",
       " 'bbb',\n",
       " 'abbbbb',\n",
       " 'aabbb',\n",
       " 'bbabaa',\n",
       " 'bbabaabbaaa',\n",
       " 'aba',\n",
       " 'aa',\n",
       " 'bababaabb',\n",
       " 'aa',\n",
       " 'bbabbbbba',\n",
       " 'b',\n",
       " 'aaababbaba',\n",
       " 'aaab',\n",
       " 'bba',\n",
       " 'aabbaaabba',\n",
       " 'aaaaab',\n",
       " 'bbabbabaaa',\n",
       " 'abbabbbbaa',\n",
       " 'aaababaaaaa',\n",
       " 'bbbbbbbbbba',\n",
       " 'abaabaaabaaa',\n",
       " 'aabb',\n",
       " 'abbbabbbbb',\n",
       " 'abbbbbbabaaba',\n",
       " 'aaaababb',\n",
       " 'aaabbbaab',\n",
       " 'abbaa',\n",
       " 'ababbbabaab',\n",
       " 'aaaabba',\n",
       " 'ab',\n",
       " 'bbaabbba',\n",
       " 'bb',\n",
       " 'bbbaaa',\n",
       " 'bbbaba',\n",
       " 'baaba',\n",
       " 'bbbaaaba',\n",
       " 'aabaaa',\n",
       " 'baabababba',\n",
       " 'aabaaa',\n",
       " 'babbb',\n",
       " 'bbabbbbbb',\n",
       " 'abbb',\n",
       " 'abababaabbba',\n",
       " 'baabbbbbaba',\n",
       " 'bbaaaabababb',\n",
       " 'aabaabaaaaa',\n",
       " 'abbba',\n",
       " 'abaabbabbabba',\n",
       " 'bbbbbaabaaa',\n",
       " 'aaaaabbaaa',\n",
       " 'bbbabba',\n",
       " 'bbabbab',\n",
       " 'bbbbbababbaa',\n",
       " 'baaa',\n",
       " 'bbaabbabaaab',\n",
       " 'bababbbaaab',\n",
       " 'b',\n",
       " 'bababbbbaabaaa',\n",
       " 'abaaabbbb',\n",
       " 'abaaababbabab',\n",
       " 'aaaaaaa',\n",
       " 'baaaaaaabbbbaa',\n",
       " 'bbaaaaa',\n",
       " 'ababaa',\n",
       " 'ba',\n",
       " 'bba',\n",
       " 'aaaabaaabaabb',\n",
       " 'aabaab',\n",
       " 'b',\n",
       " 'aba',\n",
       " 'bb',\n",
       " 'bb',\n",
       " 'aababaabbaa',\n",
       " 'babababaababa',\n",
       " 'baabab',\n",
       " 'baaaaba',\n",
       " 'aabab',\n",
       " 'baaabbbbbbba',\n",
       " 'aaaaba',\n",
       " 'aaba',\n",
       " 'aaaabb',\n",
       " 'bbabbaaa',\n",
       " 'bbbabaababb',\n",
       " 'bbbbaaabaaab',\n",
       " 'babbbbbb',\n",
       " 'abbb',\n",
       " 'baba',\n",
       " 'abaaab',\n",
       " 'aaaaab',\n",
       " 'aabbb',\n",
       " 'abaab',\n",
       " 'aabaaa',\n",
       " 'bbaab',\n",
       " 'ababaaababa',\n",
       " 'aaaabaab',\n",
       " 'babbaa',\n",
       " 'aba',\n",
       " 'a',\n",
       " 'aabaabbb',\n",
       " 'bba',\n",
       " 'aaaabab',\n",
       " 'bbbaaabaabab',\n",
       " 'babbbaaa',\n",
       " 'aaa',\n",
       " 'bababaaabba',\n",
       " 'aaabbababbbba',\n",
       " 'bbaababaabbabb',\n",
       " 'abbbab',\n",
       " 'abbbbbbaabbbb',\n",
       " 'bb',\n",
       " 'baaabaaaabbab',\n",
       " 'ababbba',\n",
       " 'ba',\n",
       " 'b',\n",
       " 'aaabbaa',\n",
       " 'aaaaaaba',\n",
       " 'aabb',\n",
       " 'abbbbbbbbbab',\n",
       " 'baaaaab',\n",
       " 'babbabbbaaa',\n",
       " 'babbaaab',\n",
       " 'babbaababb',\n",
       " 'abaabbabbaaaaa',\n",
       " 'aa',\n",
       " 'abbbaabbab',\n",
       " 'aab',\n",
       " 'bbbbbaaaaaa',\n",
       " 'abaaabbababb',\n",
       " 'aba',\n",
       " 'bab',\n",
       " 'aabbabaabaaaa',\n",
       " 'babbbbb',\n",
       " 'aaaabaabaaaa',\n",
       " 'ababb',\n",
       " 'abaab',\n",
       " 'b',\n",
       " 'bbaabbab',\n",
       " 'abbbbbbab',\n",
       " 'aaabbaaaaa',\n",
       " 'baaabb',\n",
       " 'babb',\n",
       " 'aabbb',\n",
       " 'ba',\n",
       " 'abbabaaabb',\n",
       " 'bababaababbbab',\n",
       " 'ababb',\n",
       " 'bbabaaaaabaaab',\n",
       " 'abbabbb',\n",
       " 'baabaa',\n",
       " 'bbbbbaabbaabb',\n",
       " 'baabbbababb',\n",
       " 'baba',\n",
       " 'babaababbaabbb',\n",
       " 'bb',\n",
       " 'babaababab',\n",
       " 'ababaa',\n",
       " 'aabaabbba',\n",
       " 'aaabaaaabbbbbb',\n",
       " 'aaaa',\n",
       " 'bababbbbbb',\n",
       " 'bbaaaaaa',\n",
       " 'abababbabbaab',\n",
       " 'abaab',\n",
       " 'aaaaaaababb',\n",
       " 'bba',\n",
       " 'bbabbababaaab',\n",
       " 'bbaa',\n",
       " 'baaabbabbabaa',\n",
       " 'aaab',\n",
       " 'a',\n",
       " 'bbbabbaaababb',\n",
       " 'aababaaaaab',\n",
       " 'aab',\n",
       " 'babaa',\n",
       " 'bbaabbabbbb',\n",
       " 'babb',\n",
       " 'bbbb',\n",
       " 'bbbaabaaa',\n",
       " 'aaaabbb',\n",
       " 'baabaabaaabba',\n",
       " 'abbabbbaaaba',\n",
       " 'abbababababb',\n",
       " 'bbbbbaabaabbaa',\n",
       " 'baa',\n",
       " 'ba',\n",
       " 'ababaaa',\n",
       " 'aabb',\n",
       " 'bbabbbabbbbbb',\n",
       " 'ababbabababbba',\n",
       " 'baaababbbba',\n",
       " 'bbabababb',\n",
       " 'baaaabbabababb',\n",
       " 'baaaabbb',\n",
       " 'a',\n",
       " 'baa',\n",
       " 'abbbaabbabb',\n",
       " 'bb',\n",
       " 'a',\n",
       " 'babaabbb',\n",
       " 'bbb',\n",
       " 'babb',\n",
       " 'a',\n",
       " 'ababb',\n",
       " 'bba',\n",
       " 'bbbbbaabbabba',\n",
       " 'abbbbbbbbab',\n",
       " 'bbbabbbbb',\n",
       " 'ba',\n",
       " 'aa',\n",
       " 'aabaab',\n",
       " 'bbb',\n",
       " 'abababaabbabbb',\n",
       " 'bbbbbbaaaaaba',\n",
       " 'aabbbbaaa',\n",
       " 'babaababbbbb',\n",
       " 'abaaab',\n",
       " 'baaab',\n",
       " 'babbbbbabbaaab',\n",
       " 'bbaba',\n",
       " 'aabaaaaa',\n",
       " 'bbbbaaaabbbab',\n",
       " 'abababbaabb',\n",
       " 'baaaaabbbab',\n",
       " 'abbaa',\n",
       " 'abbbbabbaaa',\n",
       " 'aab',\n",
       " 'aa',\n",
       " 'abbaaabbaaa',\n",
       " 'bbba',\n",
       " 'baaaaabbaaa',\n",
       " 'a',\n",
       " 'aabba',\n",
       " 'baa',\n",
       " 'bbab',\n",
       " 'aaab',\n",
       " 'babaaaababbb',\n",
       " 'aab',\n",
       " 'aababbabaaab',\n",
       " 'aab',\n",
       " 'aaaaba',\n",
       " 'aabaaabb',\n",
       " 'baaaaaabbab',\n",
       " 'aab',\n",
       " 'abbbbb',\n",
       " 'abbbbbababbbab',\n",
       " 'aaaaa',\n",
       " 'baa',\n",
       " 'abbabbaaababa',\n",
       " 'aa',\n",
       " 'aabbb',\n",
       " 'ba',\n",
       " 'abbbab',\n",
       " 'bbabbbbbaab',\n",
       " 'ababbaababbbb',\n",
       " 'b',\n",
       " 'bbbbaaabababa',\n",
       " 'bbaba',\n",
       " 'bbabbaab',\n",
       " 'aababaaabbbaa',\n",
       " 'a',\n",
       " 'aababbba',\n",
       " 'baaaa',\n",
       " 'aaabaaabb',\n",
       " 'abb',\n",
       " 'ababb',\n",
       " 'bbbbaaab',\n",
       " 'abbbbbaba',\n",
       " 'aaabbbbab',\n",
       " 'b',\n",
       " 'abbbbbabbbabbb',\n",
       " 'abbbaaaab',\n",
       " 'aababaabbbb',\n",
       " 'bbaaabaaab',\n",
       " 'baaaabaabababa',\n",
       " 'bba',\n",
       " 'b',\n",
       " 'aabbbbaabbab',\n",
       " 'aababaaa',\n",
       " 'aabbaba',\n",
       " 'babbababbbaabb',\n",
       " 'bbaaaab',\n",
       " 'baabab',\n",
       " 'aabbababbaabaa',\n",
       " 'abba',\n",
       " 'baaab',\n",
       " 'aaba',\n",
       " 'baaa',\n",
       " 'a',\n",
       " 'babaaaabaaa',\n",
       " 'b',\n",
       " 'abbaaa',\n",
       " 'aababbaabb',\n",
       " 'aaaaaaabbbab',\n",
       " 'abaaaa',\n",
       " 'aaab',\n",
       " 'aaa',\n",
       " 'abbaaaa',\n",
       " 'aabaaab',\n",
       " 'aaabbaaabab',\n",
       " 'bab',\n",
       " 'bbbabbaaaabaa',\n",
       " 'bbba',\n",
       " 'aba',\n",
       " 'abab',\n",
       " 'baababbbabbb',\n",
       " 'aabbaabb',\n",
       " 'bbbaaaaba',\n",
       " 'bbb',\n",
       " 'aba',\n",
       " 'bbbbbabb',\n",
       " 'babbbbbab',\n",
       " 'aaaababaaa',\n",
       " 'bbb',\n",
       " 'bbbbbbbabab',\n",
       " 'bababaaabba',\n",
       " 'babbbbabaaba',\n",
       " 'babbbbbbbabaa',\n",
       " 'baaabbbbbb',\n",
       " 'aaaabbaaababaa',\n",
       " 'b',\n",
       " 'babbbbabb',\n",
       " 'abbbaba',\n",
       " 'aaabaaa',\n",
       " 'aabaaaaaababb',\n",
       " 'aabbbbbbaa',\n",
       " 'a',\n",
       " 'bb',\n",
       " 'babbbbbababb',\n",
       " 'ab',\n",
       " 'bb',\n",
       " 'bbabbbaa',\n",
       " 'bbbaaaaabb',\n",
       " 'baabbabaab',\n",
       " 'abaa',\n",
       " 'aabbb',\n",
       " 'aabab',\n",
       " 'bbabbbba',\n",
       " 'aabaaab',\n",
       " 'aaaabbaabbb',\n",
       " 'baabbaaabaaab',\n",
       " 'aabaababbbb',\n",
       " 'abbabbbbababa',\n",
       " 'baa',\n",
       " 'bababbbbbbbaab',\n",
       " 'bbabbaaaaba',\n",
       " 'bbaaaabab',\n",
       " 'bbbbabbbab',\n",
       " 'bbbbbabb',\n",
       " 'baa',\n",
       " 'aabbbaaaabbab',\n",
       " 'aabaabbbaabaa',\n",
       " 'bbab',\n",
       " 'aaabbabaababa',\n",
       " 'bbbbabbbbbabba',\n",
       " 'bbbaabbbbab',\n",
       " 'abbaaba',\n",
       " 'b',\n",
       " 'abaababbababab',\n",
       " 'a',\n",
       " 'bbbbaa',\n",
       " 'ababaaaabaaaa',\n",
       " 'ababbba',\n",
       " 'bbbabbb',\n",
       " 'abaabbbbbbbab',\n",
       " 'abaaaab',\n",
       " 'a',\n",
       " 'baba',\n",
       " 'abba',\n",
       " 'babb',\n",
       " 'bab',\n",
       " 'baaababaaaa',\n",
       " 'abbaababb',\n",
       " 'aaabbabbabb',\n",
       " 'aabbabbab',\n",
       " 'aaaaabaababbba',\n",
       " 'b',\n",
       " 'aabb',\n",
       " 'abaaaab',\n",
       " 'b',\n",
       " 'abbbbb',\n",
       " 'aaaabbaaa',\n",
       " 'abaaaabbaab',\n",
       " 'bbbabbabaab',\n",
       " 'abaaabbbbb',\n",
       " 'baaaab',\n",
       " 'aab',\n",
       " 'bbbbaaaabaabb',\n",
       " 'b',\n",
       " 'bbabbaabbaaa',\n",
       " 'aaababaaaabaab',\n",
       " 'abba',\n",
       " 'ababbabaaabbab',\n",
       " 'abaabaaaaaaaa',\n",
       " 'b',\n",
       " 'abaaaaa',\n",
       " 'baaabbababbabb',\n",
       " 'aba',\n",
       " 'bbaabbbba',\n",
       " 'babaaabaabab',\n",
       " 'bababb',\n",
       " 'bbaaaa',\n",
       " 'b',\n",
       " 'aababbaaabaa',\n",
       " 'bbbaaaa',\n",
       " 'bb',\n",
       " 'abbaaba',\n",
       " 'bbbbabaabaa',\n",
       " 'aabbababba',\n",
       " 'abbba',\n",
       " 'bab',\n",
       " 'abaaaaaaabb',\n",
       " 'aaaaabb',\n",
       " 'abaaabbaaaaa',\n",
       " 'aabaabbabbbba',\n",
       " 'babbaabaab',\n",
       " 'babb',\n",
       " 'aaba',\n",
       " 'baaababbbaab',\n",
       " 'abbbaabaaaabba',\n",
       " 'abbaaabbaaaaa',\n",
       " 'aaaabba',\n",
       " 'abbaaaa',\n",
       " 'babbaabaaa',\n",
       " 'abbababbbbb',\n",
       " 'abbbabbb',\n",
       " 'bbaa',\n",
       " 'b',\n",
       " 'abb',\n",
       " 'bababaabb',\n",
       " 'bbbaab',\n",
       " 'a',\n",
       " 'aaaaabbbabb',\n",
       " 'baabbaba',\n",
       " 'abbaba',\n",
       " 'aaaaab',\n",
       " 'bababbbabaab',\n",
       " 'bbbaaaabbbbbb',\n",
       " 'bba',\n",
       " 'bbaa',\n",
       " 'baabaabababb',\n",
       " 'aabababaaabb',\n",
       " 'bbaaaabaab',\n",
       " 'a',\n",
       " 'bbbbbaabbbb',\n",
       " 'ababab',\n",
       " 'aab',\n",
       " 'bbbbaaabbaa',\n",
       " 'bbbbbb',\n",
       " 'baba',\n",
       " 'baaa',\n",
       " 'baabaabbabbab',\n",
       " 'baabb',\n",
       " 'aababaaaaabbba',\n",
       " 'bbaabaabbbabba',\n",
       " 'a',\n",
       " 'bbaabbbbabbb',\n",
       " 'babbbbbbaa',\n",
       " 'aaaababbbbbba',\n",
       " 'bbabbaabaaaabb',\n",
       " 'aa',\n",
       " 'bbbaabaaa',\n",
       " 'bbaaabaabaaa',\n",
       " 'aabbaaabaab',\n",
       " 'abbaabbb',\n",
       " 'aaab',\n",
       " 'abab',\n",
       " 'baababbabbaab',\n",
       " 'abbaabb',\n",
       " 'baabbbaab',\n",
       " 'bbabbbb',\n",
       " 'baaabbaaabbbbb',\n",
       " 'b',\n",
       " 'aabb',\n",
       " 'babbabbbabbbbb',\n",
       " 'aabaaa',\n",
       " 'aaabbbbabbbba',\n",
       " 'babbabab',\n",
       " 'abbbbbaabababa',\n",
       " 'ab',\n",
       " 'baabbbbbbba',\n",
       " 'bbbbaaababbb',\n",
       " 'b',\n",
       " 'bbabbab',\n",
       " 'babaaabbbaaab',\n",
       " 'aabbaaaaabaa',\n",
       " 'bbaaa',\n",
       " 'aba',\n",
       " 'ba',\n",
       " 'aaabaaabbb',\n",
       " 'aabbabbb',\n",
       " 'abba',\n",
       " 'bab',\n",
       " 'baabbbba',\n",
       " 'abababa',\n",
       " 'abbabbaa',\n",
       " 'bbbbaabab',\n",
       " 'abaaaaabaaab',\n",
       " 'baa',\n",
       " 'aaaabaa',\n",
       " 'ababaaabbabba',\n",
       " 'aababbb',\n",
       " 'bababbbbbbbbab',\n",
       " 'babbaabbaaaa',\n",
       " 'baabbbabbb',\n",
       " 'bbabaabababbba',\n",
       " 'aababbbbaa',\n",
       " 'babbbaaaabab',\n",
       " 'abbbaababa',\n",
       " 'aaaabaabb',\n",
       " 'abbbabab',\n",
       " 'aba',\n",
       " 'abaaba',\n",
       " 'bbaaababaaaaba',\n",
       " 'baaaaa',\n",
       " 'aaabbabaab',\n",
       " 'ba',\n",
       " 'babbbbbba',\n",
       " 'babaabaaba',\n",
       " 'b',\n",
       " 'abbaaaaaab',\n",
       " 'b',\n",
       " 'a',\n",
       " 'bb',\n",
       " 'abbabb',\n",
       " 'ab',\n",
       " 'aaababb',\n",
       " 'aaab',\n",
       " 'a',\n",
       " 'aaaaab',\n",
       " 'bbba',\n",
       " 'b',\n",
       " 'b',\n",
       " 'baa',\n",
       " 'bbaabbbbbaaaba',\n",
       " 'babb',\n",
       " 'aabbaa',\n",
       " 'abababaaab',\n",
       " 'aaaababbabbb',\n",
       " 'aaaaaaabbb',\n",
       " 'abaabaaaab',\n",
       " 'a',\n",
       " 'aaaaabaaabaabb',\n",
       " 'baaabaaaba',\n",
       " 'abbbaaabaaa',\n",
       " 'abababba',\n",
       " 'baabaaabbb',\n",
       " 'abbbbba',\n",
       " 'babbbaaaa',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'bbbabb',\n",
       " 'abbaabbbaaaa',\n",
       " 'aabb',\n",
       " 'aa',\n",
       " 'babaa',\n",
       " 'baaaabbbbaaaba',\n",
       " 'bababbaaaa',\n",
       " 'abbabb',\n",
       " 'aabaabbba',\n",
       " 'baabaaaabbbbab',\n",
       " 'aaababa',\n",
       " 'abbabb',\n",
       " 'bbbbbb',\n",
       " 'babbbbaaa',\n",
       " 'aaab',\n",
       " 'abaaabb',\n",
       " 'aa',\n",
       " 'abbaa',\n",
       " 'b',\n",
       " 'abaabbbba',\n",
       " 'bababbbbb',\n",
       " 'baabbaabaaa',\n",
       " 'baaaabaabb',\n",
       " 'aabbbabbb',\n",
       " 'baa',\n",
       " 'ababababababba',\n",
       " 'babbaababaabaa',\n",
       " 'aba',\n",
       " 'bbaaaabbba',\n",
       " 'bab',\n",
       " 'abbbaabbbaba',\n",
       " 'baaababababbbb',\n",
       " 'b',\n",
       " 'aabbbbbaa',\n",
       " 'bba',\n",
       " 'ba',\n",
       " 'aaab',\n",
       " 'aabbbbbabbbb',\n",
       " 'ba',\n",
       " 'ab',\n",
       " 'bbaab',\n",
       " 'ab',\n",
       " 'baabbabaabbb',\n",
       " 'baabbaaabb',\n",
       " 'bbbabaaabbbabb',\n",
       " 'bbabb',\n",
       " 'aaa',\n",
       " 'a',\n",
       " 'aaaaaaaaabb',\n",
       " 'bbbabbbba',\n",
       " 'a',\n",
       " 'bbaaaa',\n",
       " 'ba',\n",
       " 'bb',\n",
       " 'abbaaa',\n",
       " 'a',\n",
       " 'abbbb',\n",
       " 'bb',\n",
       " 'bbaaa',\n",
       " 'abbbab',\n",
       " 'bbabbbbaabbaab',\n",
       " 'abbbbaabb',\n",
       " 'b',\n",
       " 'abbaaab',\n",
       " 'bbaa',\n",
       " 'ababbaba',\n",
       " 'bbaabb',\n",
       " 'aaaba',\n",
       " 'aaaabaaa',\n",
       " 'abbababaa',\n",
       " 'bbbbab',\n",
       " 'bbabbabbaab',\n",
       " 'abbaabbaa',\n",
       " 'abb',\n",
       " 'bbbaaaaaababaa',\n",
       " 'a',\n",
       " 'bbaba',\n",
       " 'bbabbbbbabaaa',\n",
       " 'bbabaabbbabaa',\n",
       " 'aaa',\n",
       " 'a',\n",
       " 'abbaaabbbbaaa',\n",
       " 'abbaaababab',\n",
       " 'babbaaabbba',\n",
       " 'bbbabaaaaa',\n",
       " 'babba',\n",
       " 'babbbaab',\n",
       " 'bbaabab',\n",
       " 'baaaabbabba',\n",
       " 'bbaaabbaabb',\n",
       " 'aababbaa',\n",
       " 'abbb',\n",
       " 'bbbbaba',\n",
       " 'abaaaabaabbbaa',\n",
       " 'bbbbbbaaaa',\n",
       " 'b',\n",
       " 'aabaaabbabb',\n",
       " 'aaaa',\n",
       " 'aaababbbaabaa',\n",
       " 'b',\n",
       " 'baaa',\n",
       " 'babaabbaab',\n",
       " 'abbabaaaabaaa',\n",
       " 'aaba',\n",
       " 'bbaabbabbaba',\n",
       " 'aba',\n",
       " 'bababbbbbabbaa',\n",
       " 'babbbabb',\n",
       " 'abbabba',\n",
       " 'aaaa',\n",
       " 'baaabbaa',\n",
       " 'babbbbaabbbaa',\n",
       " 'aaabbababbbbaa',\n",
       " 'aabbaaaaaba',\n",
       " 'baaaaaba',\n",
       " 'ababbb',\n",
       " 'aabababbaabaa',\n",
       " 'aaaabbbabbbaa',\n",
       " 'abaaaabaab',\n",
       " 'aaabbbab',\n",
       " 'baaaabbaabbaa',\n",
       " 'abbaaaa',\n",
       " 'baaa',\n",
       " 'ababbbbbabaaba',\n",
       " 'baaabb',\n",
       " 'abaaaa',\n",
       " 'bbbaba',\n",
       " 'abaabbabbaab',\n",
       " 'b',\n",
       " 'bbbbbaaba',\n",
       " 'abaaaaababb',\n",
       " 'aa',\n",
       " 'abbbbbbbaaab',\n",
       " 'a',\n",
       " 'babb',\n",
       " 'bbaababbbabba',\n",
       " 'baabbbbbababa',\n",
       " 'aaaaaababaaa',\n",
       " 'a',\n",
       " 'bbbbbbaab',\n",
       " 'a',\n",
       " 'bb',\n",
       " 'bbbbbbababaaa',\n",
       " 'baabbaaaabbb',\n",
       " 'baaaaaababbabb',\n",
       " 'bbabbabb',\n",
       " 'abbbabaaaabab',\n",
       " 'baab',\n",
       " 'abbbababaabab',\n",
       " 'bbabbbaaaaa',\n",
       " 'abbababaaaba',\n",
       " 'aab',\n",
       " 'babababba',\n",
       " 'babaa',\n",
       " 'aababaaaabbba',\n",
       " 'abaab',\n",
       " 'aab',\n",
       " 'abab',\n",
       " 'aababbb',\n",
       " 'bbaaaba',\n",
       " 'a',\n",
       " 'abaaabbb',\n",
       " 'bbbbabba',\n",
       " 'a',\n",
       " 'bbaa',\n",
       " 'baabaaabaaab',\n",
       " 'abababbaabbaaa',\n",
       " 'b',\n",
       " 'aab',\n",
       " 'aababababaab',\n",
       " 'bababbaabababb',\n",
       " 'ababa',\n",
       " 'bba',\n",
       " 'aabbaaabab',\n",
       " 'abbaaa',\n",
       " 'baaabbaabbaa',\n",
       " 'bbbb',\n",
       " 'bababba',\n",
       " 'baababbaabbbbb',\n",
       " 'bbbbbba',\n",
       " 'babaaaba',\n",
       " 'babbbbababa',\n",
       " 'abbbabbbbaab',\n",
       " 'aa',\n",
       " 'aababbbababaaa',\n",
       " 'abbab',\n",
       " 'bbaabbbbbbab',\n",
       " 'aabaaaaabbbabb',\n",
       " 'aabbbbaaaa',\n",
       " 'ab',\n",
       " 'bababbbbbba',\n",
       " 'babaaababb',\n",
       " 'ababbabaaaaba',\n",
       " 'bbbbbababaaabb',\n",
       " 'ababbbabaa',\n",
       " 'aab',\n",
       " 'babbb',\n",
       " 'bbabbbb',\n",
       " 'ab',\n",
       " 'aaaab',\n",
       " 'bbbaaaab',\n",
       " 'bbbbaaaa',\n",
       " 'a',\n",
       " 'bbaaa',\n",
       " 'babbbababb',\n",
       " 'abb',\n",
       " 'abaa',\n",
       " 'aab',\n",
       " 'ba',\n",
       " 'bababbbbbbbbb',\n",
       " 'babbbbaabbb',\n",
       " 'babbaaabab',\n",
       " 'aabbababa',\n",
       " 'aabababbbaba',\n",
       " 'bbbbbba',\n",
       " 'abbbbaaaababbb',\n",
       " 'aaa',\n",
       " 'abbbabaab',\n",
       " 'bbbabbaabbaabb',\n",
       " 'bbaaaaa',\n",
       " 'aaa',\n",
       " 'abbbabaaaab',\n",
       " 'ab',\n",
       " 'bbbb',\n",
       " 'baaa',\n",
       " 'aaababbaaba',\n",
       " 'abaaa',\n",
       " 'bbbbbbbaaaa',\n",
       " 'bbbaba',\n",
       " 'bba',\n",
       " 'ababaabbabaa',\n",
       " 'bbbbbabb',\n",
       " 'bbabbaabaaabb',\n",
       " 'aabbbbbbbbbab',\n",
       " 'baabba',\n",
       " 'abbbaaaa',\n",
       " 'abaabbbaaa',\n",
       " 'b',\n",
       " 'abbba',\n",
       " 'aabaabaaaa',\n",
       " 'aa',\n",
       " 'bbbaaab',\n",
       " 'abaabaaaab',\n",
       " 'baabbbbabaaaba',\n",
       " 'baaaabbbbabbaa',\n",
       " 'baa',\n",
       " 'a',\n",
       " 'bbaaaabbab',\n",
       " 'aaaaaaaabaa',\n",
       " 'abaaab',\n",
       " 'bbbaaa',\n",
       " 'b',\n",
       " 'bba',\n",
       " 'baabbabbabbab',\n",
       " 'bbbaaabbb',\n",
       " 'abba',\n",
       " 'aabbaaaabba',\n",
       " 'bbaaaaba',\n",
       " 'ababbb',\n",
       " 'ababbbaaaaab',\n",
       " 'abaaababbabb',\n",
       " 'bbabaaab',\n",
       " 'abbbbbbabbbba',\n",
       " 'abbaabbbbabaa',\n",
       " 'b',\n",
       " 'aabbaaa',\n",
       " 'a',\n",
       " 'baabbbbb',\n",
       " 'b',\n",
       " 'bbabaaaabab',\n",
       " 'b',\n",
       " 'babababbbbb',\n",
       " 'a',\n",
       " 'babaa',\n",
       " 'bbbbbabaabbb',\n",
       " 'baaabbaa',\n",
       " 'bbaab',\n",
       " 'baabbb',\n",
       " 'ba',\n",
       " 'aaabaab',\n",
       " 'abaaaabba',\n",
       " 'aabbaaabaabbb',\n",
       " 'bbaabbabbabbaa',\n",
       " 'bbaabbbbbb',\n",
       " 'bb',\n",
       " 'baaababbaaba',\n",
       " 'abbababaabbbab',\n",
       " 'babbaa',\n",
       " 'bababbbaaaa',\n",
       " 'aababbbbb',\n",
       " 'baaaaaa',\n",
       " 'aaabbab',\n",
       " 'aabbbbabaaaab',\n",
       " 'ababbbaaabbaa',\n",
       " 'abbb',\n",
       " 'bbababbbaaaa',\n",
       " 'bbbbbba',\n",
       " 'baabbab',\n",
       " 'bbbbbbbb',\n",
       " 'baabababbaaa',\n",
       " 'abbba',\n",
       " 'aaba',\n",
       " 'bbbababbbbba',\n",
       " 'aaa',\n",
       " 'baaaabbbbabbba',\n",
       " 'baa',\n",
       " 'baaababaabaab',\n",
       " 'aba',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_data\n",
    "corpus, labels = get_data('dataset0.txt')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidian(h1, h2):\n",
    "    assert len(h1) == len(h2)\n",
    "    distance = 0\n",
    "    for i in range(len(h1)):\n",
    "        distance += (h1[i] - h2[i])**2\n",
    "    distance = distance**(1/2)\n",
    "    return distance\n",
    "\n",
    "euclidian([1,0], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9, 9, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "rer = [random.randrange(2,20)]*4\n",
    "rer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ids = range(7)\n",
    "acc = []\n",
    "all_merge = [358, 332, 364, 360, 422, 305, 366]\n",
    "correct_merge = [358, 332, 364, 360, 422, 285, 362]\n",
    "\n",
    "plt.plot(ids, all_merge, 'b', label='All the merges')\n",
    "plt.plot(ids, correct_merge, 'g', label='Correct merges')\n",
    "plt.title('Difference between All merges and provoqued merges')\n",
    "plt.xlabel('FSMs IDs')\n",
    "plt.ylabel('Amount of merge')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
