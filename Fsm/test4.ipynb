{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import date\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from mealy_trie import Trie\n",
    "from mealy_machine import Mealy\n",
    "from utils import *\n",
    "from mealy_machine import Mealy\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from model import Tagger, load_weights\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fsm_from_dict(id, dict, labels, nfa=False):\n",
    "    t = Trie(dict, labels)\n",
    "    my_mealy = Mealy(id, t.root.id, t.states, t.arcs)\n",
    "    # states are represented in a dfs fashion\n",
    "    return my_mealy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--id\", type=int, default=0)\n",
    "    parser.add_argument(\"--train_length\", type=int, default=10)\n",
    "    parser.add_argument(\"--n_train_low\", type=int, default=2)\n",
    "    parser.add_argument(\"--n_train_high\", type=int, default=300)\n",
    "    parser.add_argument(\"--sim_threshold\", type=float, default=.9)\n",
    "    parser.add_argument(\"--find_threshold\", default=False, action=argparse.BooleanOptionalAction)\n",
    "    parser.add_argument(\"--seeds\", type=int, default=1)\n",
    "    parser.add_argument(\"--hidden_size\", type=float, default=10)\n",
    "    parser.add_argument('--eval', type=str, default=\"labels\")\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "******************** ID 0:  EXTRACTION OF MEALY MACHINE FROM RNN ********************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id = 0\n",
    "print('\\n\\n\\n'+'*'*20+f' ID {id}: '+' EXTRACTION OF MEALY MACHINE FROM RNN '+'*'*20+'\\n\\n\\n')\n",
    "\n",
    "init_train_acc, init_dev_acc, train_acc, dev_acc = {}, {}, {}, {}\n",
    "train_acc[\"0\"] = []\n",
    "n_train = range(1)\n",
    "\n",
    "fsm_filepath = f'./FSMs/fsm{id}.txt'\n",
    "expected_fsm = getFsm(fsm_filepath)\n",
    "\n",
    "data_filepath = f'./datasets/dataset{id}.txt'\n",
    "    \n",
    "corpus, labels = get_data(data_filepath)\n",
    "assert(len(corpus) == len(labels))\n",
    "max_length = len(max(corpus, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some words of our dataset\n",
      "Corpus: ['bba', 'abbabbbbba', 'aabaaba', 'bb', 'aa']\n",
      "Labels: ['111', '1011011111', '1001001', '11', '10']\n"
     ]
    }
   ],
   "source": [
    "print('Some words of our dataset')\n",
    "print(f'Corpus: {corpus[:5]}')\n",
    "print(f'Labels: {labels[:5]}')\n",
    "\n",
    "split_index = 100\n",
    "dev_corpus = corpus[split_index:]\n",
    "dev_labels = labels[split_index:]\n",
    "\n",
    "\n",
    "corpus = corpus[:split_index]\n",
    "labels = labels[:split_index]\n",
    "\n",
    "corpus_, labels_ = preprocessing(corpus, labels, max_length)\n",
    "dev_corpus_, dev_labels_ = preprocessing(dev_corpus, dev_labels, max_length)\n",
    "\n",
    "dev_mask = [masking(x,'2') for x in dev_labels_]\n",
    "\n",
    "labels__ = np.array([np.array(list(x)) for x in labels_])\n",
    "mask = [masking(x) for x in corpus_]\n",
    "\n",
    "x_train = np.array([tokenization(x) for x in corpus_])\n",
    "train_sents = [tokenization(x) for x in corpus]\n",
    "y_train = np.array([class_mapping(x) for x in labels_])\n",
    "mask_ = np.array([masking(x) for x in corpus_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[FData Preprocessing... Done\n",
      "\n",
      "\u001b[FModel definition... Done\n",
      "\n",
      "\u001b[FModel Update... Done\n",
      "\n",
      "4/4 [==============================] - 1s 15ms/step\n",
      "['111', '1011011111', '1001001', '11', '10']\n",
      "\u001b[FTrie Building... Done\n",
      "\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 10)          40        \n",
      "                                                                 \n",
      " simple_rnn_9 (SimpleRNN)    (None, None, 10)          210       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, None, 3)           33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283\n",
      "Trainable params: 283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[FData Preprocessing... Done\\n\")\n",
    "\n",
    "trained_model = Tagger(4, 10, 10, 3)\n",
    "trained_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filename = f'./weights/weights{id}.txt'\n",
    "with open(filename, 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "\n",
    "print('\\033[FModel definition... Done\\n')\n",
    "\n",
    "trained_model.set_weights(weights)\n",
    "\n",
    "print('\\033[FModel Update... Done\\n')\n",
    "\n",
    "predictions = trained_model.predict(x_train)\n",
    "\"\"\"predictions = predictions.argmax(axis=-1)\n",
    "pred_labels = nparray_to_string(predictions, mask)\n",
    "print(pred_labels[:5])\"\"\"\n",
    "pred_labels =0\n",
    "print(labels[:5])\n",
    "\n",
    "print('\\033[FTrie Building... Done\\n')\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of states of the Trie: 214\n",
      "\n",
      "\n",
      "********************* Prefix Tree of Mealy Machine corpus **********************\n",
      "\n",
      "\n",
      "Number of states: 214\n",
      "Number of transitions: 213\n",
      "Initial state: 0\n",
      "Input vocabulary: ['b', 'a']\n",
      "Output vocabulary: ['1', '0']\n",
      "\n",
      "\n",
      "First 10 over 213 transitions of the Tree: \n",
      "-> 0 --> b/1 --> 1\n",
      "-> 1 --> b/1 --> 2\n",
      "-> 2 --> a/1 --> 3\n",
      "-> 0 --> a/1 --> 4\n",
      "-> 4 --> b/0 --> 5\n",
      "-> 5 --> b/1 --> 6\n",
      "-> 6 --> a/1 --> 7\n",
      "-> 7 --> b/0 --> 8\n",
      "-> 8 --> b/1 --> 9\n",
      "-> 9 --> b/1 --> 10\n",
      "\n",
      "********************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval = 'labels'\n",
    "if eval == 'preds' :\n",
    "    redundant_fsm = build_fsm_from_dict(id, corpus, pred_labels)\n",
    "    #assert(score_all_prefixes(redundant_fsm, corpus, labels) == 100.0), '\\nPredictions are not the same with labels'\n",
    "else:\n",
    "    redundant_fsm = build_fsm_from_dict(id, corpus, labels)\n",
    "    #assert(score_all_prefixes(redundant_fsm, corpus, pred_labels) == 100.0), '\\nLabels are not the same with predictions'\n",
    "#redundant_fsm.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[FChecking if the trie get the right ouput for each input... Done\n",
      "\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "print('\\033[FChecking if the trie get the right ouput for each input... Done\\n')\n",
    "\n",
    "trained_model.pop()\n",
    "trained_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#new_model = deepcopy(trained_model)\n",
    "#print(new_model.summary())\n",
    "representations = trained_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 12, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9863178e-01 5.1860930e-04 8.4957550e-04]\n",
      " [3.8189924e-04 9.9900287e-01 6.1517052e-04]\n",
      " [4.4097751e-04 9.9894959e-01 6.0941861e-04]\n",
      " [6.0455268e-04 9.9828053e-01 1.1149200e-03]\n",
      " [9.9985671e-01 4.3103890e-05 1.0009547e-04]\n",
      " [9.9985230e-01 6.4483196e-05 8.3235398e-05]\n",
      " [9.9986792e-01 6.5048866e-05 6.7045614e-05]\n",
      " [9.9986625e-01 6.7022040e-05 6.6779590e-05]\n",
      " [9.9986839e-01 6.6663924e-05 6.4961052e-05]\n",
      " [9.9986839e-01 6.6744593e-05 6.4825021e-05]\n",
      " [9.9986851e-01 6.6726396e-05 6.4721251e-05]\n",
      " [9.9986851e-01 6.6728557e-05 6.4704283e-05]]\n",
      "[-0.17211303  0.26192328  0.85746074 -0.09794594 -0.67063165  0.48278904\n",
      " -0.94284075 -0.9149922  -0.9720395  -0.5291131 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.17211303,  0.26192328,  0.85746074, -0.09794594, -0.67063165,\n",
       "        0.48278904, -0.94284075, -0.9149922 , -0.9720395 , -0.5291131 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions[0])\n",
    "print(representations[0][0])\n",
    "representations[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[FGetting states... Done\n",
      "\n",
      "\u001b[FStates Mapping preparation... Done\n",
      "\n",
      "['bba', 'abbabbbbba', 'aabaaba', 'bb', 'aa']\n",
      "[[ True  True  True  True False False False False False False False False]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True  True  True False False False False]\n",
      " [ True  True  True False False False False False False False False False]\n",
      " [ True  True  True False False False False False False False False False]]\n",
      "[[-0.17211303  0.26192328  0.85746074 -0.09794594 -0.67063165  0.48278904\n",
      "  -0.94284075 -0.9149922  -0.9720395  -0.5291131 ]\n",
      " [ 0.36985126  0.38259214 -0.5516439  -0.86095196  0.8985502   0.8429272\n",
      "   0.91613066 -0.8990081   0.685846    0.06565572]\n",
      " [ 0.57503617  0.44572073 -0.46135584 -0.90672046  0.85027635  0.82383704\n",
      "   0.8736894  -0.80343986  0.6629787   0.18829003]\n",
      " [ 0.96302897  0.93109095 -0.7505582   0.08382813  0.7523115   0.90976954\n",
      "   0.8970763   0.69255567  0.9068847  -0.60051644]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3],\n",
       " [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
       " [0, 4, 14, 15, 16, 17, 18, 19],\n",
       " [0, 1, 2],\n",
       " [0, 4, 14]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('\\033[FGetting states... Done\\n')\n",
    "\n",
    "idx = [redundant_fsm.return_states(sent) for sent in corpus] # maps strings to states\n",
    "n_states = len(redundant_fsm.states)\n",
    "states = np.zeros((n_states, 10))\n",
    "states_mask = np.zeros(n_states)\n",
    "\n",
    "print('\\033[FStates Mapping preparation... Done\\n')\n",
    "print(corpus[:5])\n",
    "print(mask_[:5])\n",
    "print(representations[0][mask_[0]])\n",
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17211303,  0.26192328,  0.85746074, ..., -0.91499221,\n",
       "        -0.97203952, -0.52911311],\n",
       "       [ 0.36985126,  0.38259214, -0.55164391, ..., -0.8990081 ,\n",
       "         0.68584597,  0.06565572],\n",
       "       [ 0.57503617,  0.44572073, -0.46135584, ..., -0.80343986,\n",
       "         0.66297871,  0.18829003],\n",
       "       ...,\n",
       "       [ 0.57375389,  0.44103438, -0.40026191, ..., -0.9043811 ,\n",
       "         0.6314857 , -0.26362786],\n",
       "       [ 0.61830693,  0.51953465, -0.27519906, ..., -0.81907737,\n",
       "         0.48997593, -0.07041915],\n",
       "       [ 0.64176989,  0.5943312 , -0.30004212, ..., -0.81972021,\n",
       "         0.54984033,  0.02144895]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, _r in enumerate(representations):\n",
    "    states[idx[i]] = _r[mask_[i]]\n",
    "    states_mask[idx[i]] = labels__[i][mask_[i]]\n",
    "states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
