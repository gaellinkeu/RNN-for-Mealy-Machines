{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# Accuracy ne prenant pas en compte les charactères complétés\n",
    "\n",
    "# Remove this when the cosineSimilarity will be added\n",
    "def cosineSimilarity(h1, h2):\n",
    "    return 2.3\n",
    "\n",
    "def ignore_class_accuracy(to_ignore=2):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy\n",
    "\n",
    "# Fonction qui imitte le comportement du réseau de neurone\n",
    "def get_hidden_state (word):\n",
    "    prec = 0.005\n",
    "    output = []\n",
    "    \n",
    "    for i, char in enumerate(word):\n",
    "        if char == \"a\":\n",
    "            prec = 0.02*(i+1) + prec\n",
    "            output.append(prec)\n",
    "        elif char == \"b\":\n",
    "            prec = 0.03*(i+1) + prec\n",
    "            output.append(prec)\n",
    "        elif char == \"e\":\n",
    "            prec = 0.005*(i+1) + prec\n",
    "            output.append(prec)\n",
    "        else:\n",
    "            prec = 0.05*(i+1) + prec\n",
    "            output.append(prec)\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_data(filepath):\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    #print(lines[:3])\n",
    "\n",
    "\n",
    "    #max_length = 0\n",
    "\n",
    "    for line in lines:\n",
    "        res = \"\"\n",
    "        isInput = True\n",
    "        for symbol in line:\n",
    "            if symbol in [',', '\\n']:\n",
    "                if isInput:\n",
    "                    inputs.append(res)\n",
    "                    #max_length = len(res) if len(res) > max_length else max_length\n",
    "                    res = \"\"\n",
    "                    isInput = not isInput\n",
    "                    continue\n",
    "                else:\n",
    "                    outputs.append(res)\n",
    "            res += symbol\n",
    "        #print(line)\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "def class_mapping(label, numb_class = 3):\n",
    "    y_train = []\n",
    "    for x in label:\n",
    "        assert int(x) < numb_class\n",
    "        y_train.append([int(i==int(x)) for i in range(numb_class)])\n",
    "        \n",
    "    return y_train\n",
    "\n",
    "def tokenization(word, num_token = 4):\n",
    "    x_train = []\n",
    "    for x in word:\n",
    "        if x == 'a':\n",
    "            x_train.append(1)\n",
    "        elif x == 'b':\n",
    "            x_train.append(2)\n",
    "        elif x == 'e':\n",
    "            x_train.append(3)\n",
    "        else:\n",
    "            x_train.append(0)\n",
    "    \n",
    "    return x_train\n",
    "\n",
    "def masking(word, pad_char = 'z'):\n",
    "    return [x!=pad_char for x in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Embedding\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def Tagger(n_tokens = 4, embedding_vector_length = 10, hidden_dim = 10, n_labels = 3, return_states = False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(n_tokens, embedding_vector_length))\n",
    "    model.add(SimpleRNN(hidden_dim, return_sequences=True))\n",
    "    if not return_states:\n",
    "        model.add(Dense(n_labels, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# These two functions work only for the specified configuration of the network\n",
    "\"\"\"def save_weights(model, filename):\n",
    "    weights = []\n",
    "    for layer in model.layers:\n",
    "        w = []\n",
    "        [w.append(x.tolist()) for x in layer.get_weights()]\n",
    "        weights.append(w)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(weights, f)\"\"\"\n",
    "\n",
    "def load_weights(model, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        weights = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "******************** ID 0:  TRAINING THE RECURRENT NEURAL NETWORK ********************\n",
      "\n",
      "\n",
      "\n",
      "The corpus is ['bba', 'abbabbbbba', 'aabaaba', 'bb', 'aa']\n",
      "The labels are ['111', '1011011111', '1001001', '11', '10']\n",
      "\n",
      "The length of corpus is: 800\n",
      "\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 3s 11ms/step - loss: 1.0313 - accuracy: 0.5796\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.8874 - accuracy: 0.7040\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7764 - accuracy: 0.7040\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6882 - accuracy: 0.7056\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6150 - accuracy: 0.7746\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4724 - accuracy: 0.8904\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.9312\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3357 - accuracy: 0.9592\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9778\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9845\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1940 - accuracy: 0.9870\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1638 - accuracy: 0.9874\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1396 - accuracy: 0.9908\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1201 - accuracy: 0.9950\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.9968\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9981\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.9989\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0698 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 1.0000\n",
      "\n",
      "\n",
      " The categorical crossentropy loss: 0.06182641535997391\n",
      "\n",
      "\n",
      " The accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "id = 0\n",
    "print('\\n\\n\\n'+'*'*20+f' ID {id}: '+' TRAINING THE RECURRENT NEURAL NETWORK '+'*'*20+'\\n\\n\\n')\n",
    "#max_length = 4\n",
    "#corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb']\n",
    "#labels = ['11', '1', '1', '110', '1', '1100', '10', '1', '1010', '101', '11']\n",
    "corpus, labels = get_data(f'./datasets/dataset{id}.txt')\n",
    "\n",
    "\n",
    "max_length = len(max(corpus, key=len))\n",
    "\n",
    "print(f'The corpus is {corpus[:5]}')\n",
    "print(f'The labels are {labels[:5]}')\n",
    "dev_percentage = 0.2\n",
    "dev_size = int(dev_percentage * len(corpus))\n",
    "dev_corpus = corpus[len(corpus) - dev_size:]\n",
    "dev_labels = labels[len(corpus) - dev_size:]\n",
    "dev_max_length = len(max(dev_corpus, key=len))\n",
    "\n",
    "corpus = corpus[:len(corpus) - dev_size]\n",
    "labels = labels[:len(labels) - dev_size]\n",
    "corpus_, labels_ = preprocessing(corpus, labels, max_length)\n",
    "dev_corpus_, dev_labels_ = preprocessing(dev_corpus, dev_labels, dev_max_length)\n",
    "\n",
    "dev_mask = [masking(x) for x in dev_corpus_]\n",
    "\n",
    "\"\"\"corpus_ = [\"e\"+x+\"z\"*(max_length - len(x)) for x in corpus]\n",
    "labels_ = [\"0\"+x+\"2\"*(max_length - len(x)) for x in labels]\"\"\"\n",
    "states = []\n",
    "print(f'\\nThe length of corpus is: {len(corpus)}\\n')\n",
    "\n",
    "x_train = np.array([tokenization(x) for x in corpus_])\n",
    "y_train = np.array([class_mapping(x) for x in labels_])\n",
    "\n",
    "x_test = np.array([tokenization(x) for x in dev_corpus_])\n",
    "y_test = np.array([class_mapping(x) for x in dev_labels_])\n",
    "\n",
    "mask = np.array([masking(x) for x in corpus_])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"version_name = '01'\n",
    "model_dir = os.path.join(\"weigths\", version_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "filepath = \"weigths/model_weights.h5\\\"\"\"\"\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "batch_size = 50\n",
    "n_epochs = 20\n",
    "\n",
    "model = Tagger(4, 10, 10, 3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size, n_epochs)\n",
    "# bacth de taille 2\n",
    "\n",
    "loss = history.history['loss'][-1]\n",
    "accuracy = history.history['accuracy'][-1]\n",
    "#print('\\n\\n\\n Les prédictions sont: \\n\\n')\n",
    "#print(train_preds)\n",
    "\n",
    "print(f'\\n\\n The categorical crossentropy loss: {loss}')\n",
    "print(f'\\n\\n The accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 1 3 3 3 3 3 3 3 3 3]\n",
      " [2 0 1 1 0 0 1 0 3 3 3 3]\n",
      " [2 1 1 0 1 1 0 0 3 3 3 3]\n",
      " [2 1 1 1 3 3 3 3 3 3 3 3]\n",
      " [2 0 0 0 0 0 0 0 0 3 3 3]]\n",
      "[[[1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]\n",
      "  [1 0 0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(list_, mask):\n",
    "    string = ''\n",
    "    for i, x in enumerate(list_):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if mask[i]:\n",
    "            string += f'{x}'\n",
    "    return string\n",
    "\n",
    "def nparray_to_string(predictions, mask):\n",
    "    preds = predictions.tolist()\n",
    "    labels = []\n",
    "    for i, x in enumerate(preds):\n",
    "        labels.append(list_to_string(x, mask[i]))\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dev_corpus_:\n",
    "    if len(i) != 12:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, False, False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True, True, True, True, True, True, True, True, True, False, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, True, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True, True, True, True, True, True, True, True, True, True, False, False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dev_mask:\n",
    "    if len(i) != 12:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gael\\AppData\\Local\\Temp\\ipykernel_8976\\3189468442.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(np.asarray(dev_mask).shape)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(dev_mask).shape)\n",
    "print(predictions.argmax(axis=-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['10', '1011001', '1110110', '111', '10000000']\n",
      "['10', '1011001', '1110110', '111', '10000000']\n",
      "['10', '1011001', '1110110', '111', '10000000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = predictions.argmax(axis=-1)\n",
    "#label = y.join()\n",
    "x = y.tolist()\n",
    "#print(y.shape)\n",
    "print(x[0])\n",
    "#print(y_test.argmax(axis=-1))\n",
    "#final_label = [idx_to_label[i] for i in y.detach().cpu().numpy()]\n",
    "#print(final_label)\n",
    "#predictions[:5]\n",
    "uy = nparray_to_string(y, dev_mask)\n",
    "print(uy[:5])\n",
    "print(nparray_to_string(y_test[:5].argmax(axis=-1), dev_mask[:5]))\n",
    "print(dev_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3788919903.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[63], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    assert(2 == 2) 'Ce nest pas '\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "assert(2 == 2) 'Ce nest pas '\n",
    "rr = [2, 3,4]\n",
    "rr.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type if scores is [0.07397884130477905, 1.0]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Type if scores is {scores}\")\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m labels \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor([[[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],\n\u001b[0;32m      4\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m]],\n\u001b[0;32m      5\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],\n\u001b[0;32m      6\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],\n\u001b[0;32m      7\u001b[0m                                 [[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]]])\n\u001b[1;32m----> 9\u001b[0m logits \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor([[[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]],\n\u001b[0;32m     10\u001b[0m                                 [[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m]],\n\u001b[0;32m     11\u001b[0m                                 [[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]],\n\u001b[0;32m     12\u001b[0m                                 [[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]],\n\u001b[0;32m     13\u001b[0m                                 [[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m],[\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m0.1\u001b[39;49m,\u001b[39m0.9\u001b[39;49m]]])\n\u001b[0;32m     15\u001b[0m bool_acc \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mequal(tf\u001b[39m.\u001b[39margmax(logits, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), tf\u001b[39m.\u001b[39margmax(labels, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     16\u001b[0m accuracy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mcast(bool_acc, tf\u001b[39m.\u001b[39mfloat32))\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "labels = tf.convert_to_tensor([[[1,0,0],[1,0,0],[0,0,1]],\n",
    "                                [[0,1,0],[1,0,0],[0,1,0]],\n",
    "                                [[0,0,1],[0,0,1],[0,0,1]],\n",
    "                                [[0,1,0],[1,0,0],[0,0,1]],\n",
    "                                [[0,0,1],[0,1,0],[0,0,1]]])\n",
    "\n",
    "logits = tf.convert_to_tensor([[[0.1,0.9,0],[0.1,9,0,0],[0,0.1,0.9]],\n",
    "                                [[0.1,0.9,0],[0.1,9,0,0],[0.1,0.9,0]],\n",
    "                                [[0,0.1,0.9],[0,0.1,0.9],[0,0.1,0.9]],\n",
    "                                [[0.1,0.9,0],[0.1,9,0,0],[0,0.1,0.9]],\n",
    "                                [[0,0.1,0.9],[0.1,0.9,0],[0,0.1,0.9]]])\n",
    "\n",
    "bool_acc = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "accuracy = tf.reduce_mean(tf.cast(bool_acc, tf.float32))\n",
    "\n",
    "print(accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baby come over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.3>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create an optimizer.\n",
    "opt = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n",
    "var1, var2 = tf.Variable(1.0), tf.Variable(2.0)\n",
    "\n",
    "# Compute the gradients for a list of variables.\n",
    "with tf.GradientTape() as tape:\n",
    "  loss = 3 * var1 * var1 + 2 * var2 * var2\n",
    "grads = tape.gradient(loss, [var1, var2])\n",
    "\n",
    "# Process the gradients.\n",
    "grads[0] = grads[0] + 1\n",
    "\n",
    "# Ask the optimizer to apply the gradients on variables.\n",
    "opt.apply_gradients(zip(grads, [var1, var2]))\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_prefix(mealy, dataset, labels):\n",
    "    # A bunch of code on how to determine if a label correctly corresponds\n",
    "    # to the output of the mealy machine\n",
    "    scores = 0\n",
    "    total = 0\n",
    "    for i in range(len(dataset)):\n",
    "        output = mealy.return_output(dataset[i])\n",
    "        print(output)\n",
    "        score = [labels[i][j] == output[j] for j in range(len(output))]\n",
    "        scores += score.count(True)\n",
    "        total += len(output)\n",
    "\n",
    "    return scores/total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 'a', '0', 3], [1, 'b', '0', 3], [0, 'b', '0', 3]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "a = ['eaaab', 'ebabb', 'eaac', 'eaab']\n",
    "b = ['00001', '01011', '0001', '0010']\n",
    "arcs = [[2,'a', '0', 3],[1,'b', '0', 3],[2,'a', '0', 3],[0,'b', '0', 3],[1,'b', '0', 3],]\n",
    "\n",
    "class Mealy(object):\n",
    "\n",
    "    def __init__(self, id, root, nodes, arcs):\n",
    "        # nodes = [0,1,2,...]\n",
    "        # arcs = [(0,a,1,1), ...]\n",
    "        self.id = id\n",
    "        self.root =  root\n",
    "        self.nodes = nodes\n",
    "        self.transitions = [list(x) for x in arcs]\n",
    "        self.inputAlphabet = []\n",
    "        self.outputAlphabet = []\n",
    "\n",
    "        for x in self.transitions:\n",
    "            if x[1] not in self.inputAlphabet:\n",
    "                self.inputAlphabet.append(x[1])\n",
    "            if x[2] not in self.outputAlphabet:\n",
    "                self.outputAlphabet.append(x[2])\n",
    "    \n",
    "    def output(self, initial_state, input_char):\n",
    "        for x in self.transitions:\n",
    "            if x[0] == initial_state and x[1] ==  input_char:\n",
    "                return (x[2], x[3])\n",
    "        return None\n",
    "\n",
    "    def getInpOut(self, node):\n",
    "        inp_out = []\n",
    "        for x in self.transitions:\n",
    "            if x[0] == node:\n",
    "                inp_out.append([x[1],x[2]])\n",
    "        \n",
    "        return inp_out\n",
    "\n",
    "    # get the output of the machine given a word\n",
    "    def return_output(self, word):\n",
    "        # we consider that the word comes without the bos sign\n",
    "        output = ''\n",
    "        idx = self.root\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx, word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx} with {word[i]}')\n",
    "            break\n",
    "           output += self.output(idx, word[i])[0]\n",
    "           idx = self.output(idx, word[i])[1]\n",
    "        return output\n",
    "    \n",
    "    # get the trace of the machine given a word\n",
    "    def return_states(self, word):\n",
    "        \n",
    "        # we consider that the word comes without the bos sign\n",
    "        # for a word abba we have [0,1,2,3,4] for example\n",
    "        idx = [self.root]\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx[i], word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx[i]} with {word[i]}')\n",
    "            break\n",
    "           idx.append(self.output(idx[i], word[i])[1])\n",
    "        return idx\n",
    "    \n",
    "    \n",
    "    \n",
    "    def print(self):\n",
    "        print(f'\\nThe amount of states is {len(self.nodes)}')\n",
    "        #print(\"Different states of the Tree: \")\n",
    "        #for i in self.nodes:\n",
    "        #    print(f'ID: {i}\\tHidden value: {0}')\n",
    "\n",
    "        print(f'The amount of Transitions is {len(self.transitions)}')\n",
    "        print(f\"\\nFirst {len(self.transitions)} Transitions of the FSM\")\n",
    "        if len(self.transitions) <= 10 :\n",
    "            for transition in self.transitions:\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "        else:\n",
    "            for i, transition in enumerate(self.transitions):\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "                if i == 9:\n",
    "                    break\n",
    "\n",
    "states = [1,2,3]\n",
    "arcs = [(0, 'a', '0', 0),\n",
    "        (0, 'b', '1', 1),\n",
    "        (1, 'a', '1', 1),\n",
    "        (1, 'b', '0', 2),\n",
    "        (2, 'b', '0', 0),\n",
    "        (2, 'a', '1', 1)]\n",
    "\n",
    "m = Mealy(0, 0, states, arcs)\n",
    "print(m.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb', 'abb', 'aaaa', 'baaaaab', 'abababb']\n",
    "_labels = ['11', '1', '0', '111', '0', '1111', '00', '1', '0111', '010', '10', '011', '0000', '1111110', '0110100']\n",
    "def score_whole_words(mealy, dataset, labels):\n",
    "    acc = 0\n",
    "    for word, y in zip(dataset, labels):\n",
    "        acc += (mealy.return_output(word) == y)\n",
    "    return (acc / len(dataset) * 100)\n",
    "\n",
    "_acc = score_whole_words(m, _corpus, _labels)\n",
    "_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of states is 11\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 1\n",
      "1 --> a/1 --> 2\n",
      "2 --> a/0 --> 4\n",
      "4 --> a/0 --> 5\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 7\n",
      "7 --> b/1 --> 10\n",
      "7 --> a/1 --> 8\n",
      "8 --> a/0 --> 9\n",
      "3 --> a/0 --> 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "class Mealy(object):\n",
    "\n",
    "    def __init__(self, id, root, nodes, arcs):\n",
    "        # nodes = [0,1,2,...]\n",
    "        # arcs = [(0,a,1,1), ...]\n",
    "        self.id = id\n",
    "        self.root =  root\n",
    "        self.nodes = nodes\n",
    "        self.transitions = [list(x) for x in arcs]\n",
    "        self.inputAlphabet = []\n",
    "        self.outputAlphabet = []\n",
    "\n",
    "        for x in self.transitions:\n",
    "            if x[1] not in self.inputAlphabet:\n",
    "                self.inputAlphabet.append(x[1])\n",
    "            if x[2] not in self.outputAlphabet:\n",
    "                self.outputAlphabet.append(x[2])\n",
    "    \n",
    "    def output(self, initial_state, input_char):\n",
    "        for x in self.transitions:\n",
    "            if x[0] == initial_state and x[1] ==  input_char:\n",
    "                return (x[2], x[3])\n",
    "        return None\n",
    "\n",
    "    def getInpOut(self, node):\n",
    "        inp_out = []\n",
    "        for x in self.transitions:\n",
    "            if x[0] == node:\n",
    "                inp_out.append([x[1],x[2]])\n",
    "        \n",
    "        return inp_out\n",
    "\n",
    "    # get the output of the machine given a word\n",
    "    def return_output(self, word):\n",
    "        # we consider that the word comes without the bos sign\n",
    "        output = ''\n",
    "        idx = self.root\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx, word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx} with {word[i]}')\n",
    "            break\n",
    "           output += self.output(idx, word[i])[0]\n",
    "           idx = self.output(idx, word[i])[1]\n",
    "        return output\n",
    "    \n",
    "    # get the trace of the machine given a word\n",
    "    def return_states(self, word):\n",
    "        \n",
    "        # we consider that the word comes without the bos sign\n",
    "        # for a word abba we have [0,1,2,3,4] for example\n",
    "        idx = [self.root]\n",
    "        for i in range(len(word)):\n",
    "           if self.output(idx[i], word[i]) == None:\n",
    "            print(f'There\\'s no transitions from {idx[i]} with {word[i]}')\n",
    "            break\n",
    "           idx.append(self.output(idx[i], word[i])[1])\n",
    "        return idx\n",
    "    \n",
    "    \n",
    "    \n",
    "    def print(self):\n",
    "        print(f'\\nThe amount of states is {len(self.nodes)}')\n",
    "        #print(\"Different states of the Tree: \")\n",
    "        #for i in self.nodes:\n",
    "        #    print(f'ID: {i}\\tHidden value: {0}')\n",
    "\n",
    "        print(f'The amount of Transitions is {len(self.transitions)}')\n",
    "        print(f\"\\nFirst {len(self.transitions)} Transitions of the FSM\")\n",
    "        if len(self.transitions) <= 10 :\n",
    "            for transition in self.transitions:\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "        else:\n",
    "            for i, transition in enumerate(self.transitions):\n",
    "                print(f'-> {transition[0]} --> {transition[1]}/{transition[2]} --> {transition[3]}')\n",
    "                if i == 9:\n",
    "                    break\n",
    "\n",
    "    def removeDuplicate(self):\n",
    "        add = True\n",
    "        states = []\n",
    "        for x in self.nodes:\n",
    "            if x not in states:\n",
    "                states.append(x)\n",
    "        \n",
    "        self.nodes = deepcopy(states)\n",
    "\n",
    "        transitions = [self.transitions[0]]\n",
    "        for x in self.transitions:\n",
    "            for y in transitions:\n",
    "                if x == y:\n",
    "                    add = False\n",
    "            if add:\n",
    "                transitions.append(x)\n",
    "            add = True\n",
    "        self.transitions = deepcopy(transitions)\n",
    "\n",
    "        nodes = []\n",
    "        for x in self.transitions:\n",
    "            if x[0] not in nodes:\n",
    "                nodes.append(x[0])\n",
    "            if x[3] not in nodes:\n",
    "                nodes.append(x[3])\n",
    "\n",
    "        self.nodes = deepcopy(nodes)\n",
    "        \n",
    "        \n",
    "    def merge_states(self, state1, state2):\n",
    "        \n",
    "\n",
    "        self.merging(state1, state2)\n",
    "        \n",
    "        #self.removeDuplicate()\n",
    "        self.print()\n",
    "\n",
    "\n",
    "    def merging(self, state1, state2):\n",
    "        print(f'\\n The two states are {state1} and {state2}\\n')\n",
    "        submerged = False\n",
    "        if state1 == state2:\n",
    "            return 0\n",
    "        if (state1 not in self.nodes or state2 not in self.nodes):\n",
    "            return 1\n",
    "        \n",
    "        for i in range(len(self.transitions)):\n",
    "            for j in range(len(self.transitions)):\n",
    "                if(i == j):\n",
    "                    continue\n",
    "\n",
    "                # merge the children of the two mergable states\n",
    "                if self.transitions[i][0] == state1 and self.transitions[j][0] == state2:\n",
    "                    if self.transitions[i][1:3] == self.transitions[j][1:3]:\n",
    "                        submerged = True\n",
    "                        print(f'\\n The two SUB states are {self.transitions[i][3]} and {self.transitions[j][3]}\\n')\n",
    "                        self.merging(self.transitions[i][3], self.transitions[j][3])\n",
    "\n",
    "        for i in range(len(self.transitions)):\n",
    "            if self.transitions[i][0] == state2:\n",
    "                self.transitions[i][0] = state1\n",
    "            if self.transitions[i][3] == state2:\n",
    "                self.transitions[i][3] = state1\n",
    "        \n",
    "        # If the merged is the root\n",
    "        if self.root == state2:\n",
    "            self.root = state1\n",
    "\n",
    "        # Delete the merged state\n",
    "        \"\"\"if state2 in self.nodes:\n",
    "            self.nodes.remove(state2)\"\"\"\n",
    "\n",
    "        # Remove doble transaction\n",
    "        transitions = []\n",
    "\n",
    "        \"\"\"for x in self.transitions:\n",
    "            add = True\n",
    "            for y in transitions:\n",
    "                if x == y:\n",
    "                    add = False\n",
    "            if add:\n",
    "                transitions.append(x)\n",
    "            \n",
    "        self.transitions = deepcopy(transitions)\"\"\"\n",
    "        #print(self.transitions)\n",
    "        \n",
    "        \n",
    "        #self.print()\n",
    "\n",
    "        return 0\n",
    "\n",
    "nodes = [0,1,2]\n",
    "arcs = [(0,'b','1',1),\n",
    "        (0,'a','0',0),\n",
    "        (1,'a','1',1),\n",
    "        (1,'b','0',2),\n",
    "        (2,'a','1',1),\n",
    "        (2,'b','0',0)]\n",
    "\n",
    "fsm = Mealy(0, 0, nodes, arcs)\n",
    "fsm.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 7, 10]\n",
      "101\n",
      "There's no transitions from 1 with b\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(fsm.return_states('abb'))\n",
    "print(fsm.return_output('abb'))\n",
    "print(fsm.return_states('bbb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The two states are 0 and 1\n",
      "\n",
      "The amount of states is 11\n",
      "\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 7\n",
      "7 --> b/1 --> 10\n",
      "7 --> a/1 --> 8\n",
      "8 --> a/0 --> 9\n",
      "3 --> a/0 --> 3\n",
      "\n",
      " The two states are 3 and 6\n",
      "\n",
      "The amount of states is 11\n",
      "\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 7\n",
      "7 --> b/1 --> 10\n",
      "7 --> a/1 --> 8\n",
      "8 --> a/0 --> 9\n",
      "3 --> a/0 --> 3\n",
      "\n",
      " The two states are 0 and 7\n",
      "\n",
      "\n",
      " The two SUB states are 0 and 10\n",
      "\n",
      "\n",
      " The two states are 0 and 10\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 8\n",
      "\n",
      "\n",
      " The two states are 3 and 8\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 9\n",
      "\n",
      "\n",
      " The two states are 3 and 9\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 3\n",
      "\n",
      "\n",
      " The two states are 3 and 3\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 3\n",
      "\n",
      "\n",
      " The two states are 3 and 3\n",
      "\n",
      "\n",
      " The two SUB states are 3 and 3\n",
      "\n",
      "\n",
      " The two states are 3 and 3\n",
      "\n",
      "The amount of states is 11\n",
      "\n",
      "\n",
      "The amount of arcs is 10\n",
      "\n",
      "\n",
      "Different transitions of the Tree: \n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n",
      "0 --> a/1 --> 3\n",
      "3 --> b/0 --> 0\n",
      "0 --> b/1 --> 0\n",
      "0 --> a/1 --> 3\n",
      "3 --> a/0 --> 3\n",
      "3 --> a/0 --> 3\n"
     ]
    }
   ],
   "source": [
    "#fsm.merge_states(2,4)\n",
    "#fsm.merge_states(0,1)\n",
    "#fsm.merge_states(3,6)\n",
    "#fsm.merge_states(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(states)):\n\u001b[0;32m     62\u001b[0m         sim1[i]\u001b[39m.\u001b[39mappend(cosine(states[i], states[j]))\n\u001b[1;32m---> 64\u001b[0m sim1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(sim1)\n\u001b[0;32m     65\u001b[0m \u001b[39m#print(sim1)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m fusionable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine(h1, h2):\n",
    "    cos = 0\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    assert len(h1) == len(h2)\n",
    "    for i in range(len(h1)):\n",
    "        cos += h1[i]*h2[i]\n",
    "        s1 += h1[i]**2\n",
    "        s2 += h2[i]**2\n",
    "    s1 = s1**(1/2)\n",
    "    s2 = s2**(1/2)\n",
    "    return cos/(s1*s2)\n",
    "\n",
    "\n",
    "mask = [[True, True, True, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, True, True, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, False, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, True, False]]\n",
    "labels  = np.array([[0,1,1,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,1,0,2],\n",
    "        [0,1,1,0,0],\n",
    "        [0,1,0,2,2],\n",
    "        [0,1,0,1,0],\n",
    "        [0,1,0,1,2]])\n",
    "representations = np.array([[[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.3, 4.5], [2.67, 1.01]]])\n",
    "idx = [[0,1,2], \n",
    "    [0,1],\n",
    "    [0,3],\n",
    "    [0,1,2,4],\n",
    "    [0,1,2,4,5],\n",
    "    [0,3,6],\n",
    "    [0,3,7,8,9],\n",
    "    [0,3,7,10]] # maps strings to states\n",
    "n_states = 11\n",
    "states = np.zeros((n_states, 2))\n",
    "states_mask = np.zeros(n_states)\n",
    "\n",
    "for i, _r in enumerate(representations):\n",
    "    #print(_r)\n",
    "    states[idx[i]] = _r[mask[i]]\n",
    "    states_mask[idx[i]] = labels[i][mask[i]]\n",
    "\n",
    "sim1 = []\n",
    "for i in range(len(states)):\n",
    "    sim1.append([])\n",
    "    for j in range(len(states)):\n",
    "        sim1[i].append(cosine(states[i], states[j]))\n",
    "\n",
    "sim1 = tf.convert_to_tensor(sim1)\n",
    "#print(sim1)\n",
    "\n",
    "fusionable = True\n",
    "res, pruned = 0, 0\n",
    "threshold = 1\n",
    "total = 0\n",
    "ter = 0\n",
    "\n",
    "\"\"\"while fusionable and ter < 10:\n",
    "    fusionable = False\n",
    "    ter += 1\"\"\"\n",
    "\n",
    "#fsm.print()\n",
    "\n",
    "\"\"\"for i in range(states.shape[0]):\n",
    "    for j in range(i):\n",
    "        pass_ = False\n",
    "        if(i == j):\n",
    "            continue\n",
    "        for x in fsm.getInpOut(i):\n",
    "            for y in fsm.getInpOut(j):\n",
    "                if(x[0] == y[0] and x[1] != y[1]):\n",
    "                    pass_ = True\n",
    "        #print(f'--we have {i} and {j} and the similarity {sim[i][j]}')\n",
    "        if pass_:\n",
    "            continue\n",
    "        \n",
    "        if(sim1[i][j] >= threshold):\n",
    "            print(f'The states to merge {i} and {j}')\n",
    "            fusionable = True\n",
    "            total += 1\n",
    "            res = fsm.merge_states(i, j)\n",
    "            #pruned += 1 - res\"\"\"\n",
    "    \n",
    "\n",
    "#print(states)\n",
    "#print(states_mask)\n",
    "#print(sim[0])\n",
    "#fsm.print()\n",
    "#fsm.removeDuplicate()\n",
    "#print('After Duplicate deletion')\n",
    "#fsm.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_merging(fsm, states, states_mask, threshold = 1.0):\n",
    "\n",
    "    cos = tf.keras.losses.CosineSimilarity(axis=-1)\n",
    "    sim = -cos(states[None, :, :], states[:, None, :])\n",
    "     \n",
    "    total, pruned = 0, 0\n",
    "    fsm_ = deepcopy(fsm)\n",
    "\n",
    "    for i in range(states.shape[0]):\n",
    "        for j in range(i):\n",
    "            pass_ = False\n",
    "            if(i == j):\n",
    "                continue\n",
    "            for x in fsm_.getInpOut(i):\n",
    "                for y in fsm_.getInpOut(j):\n",
    "                    if(x[0] == y[0] and x[1] != y[1]):\n",
    "                        pass_ = True\n",
    "            #print(f'--we have {i} and {j} and the similarity {sim[i][j]}')\n",
    "            if pass_:\n",
    "                continue\n",
    "            \n",
    "            if(sim[i][j] >= threshold):\n",
    "                print(f'The states to merge {i} and {j}')\n",
    "                fusionable = True\n",
    "                total += 1\n",
    "                res = fsm_.merge_states(i, j)\n",
    "                #pruned += 1 - res\n",
    "                \n",
    "    fsm_.removeDuplicate()\n",
    "    fsm_.print()\n",
    "    fsm_.id = str(fsm_.id) + 'min'\n",
    "    return fsm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 0; input has only 0 dims [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 46\u001b[0m\n\u001b[0;32m     41\u001b[0m     states_mask[idx[i]] \u001b[39m=\u001b[39m labels[i][mask[i]]\n\u001b[0;32m     43\u001b[0m \u001b[39m#cos = tf.keras.losses.CosineSimilarity(axis=-1,reduction=tf.keras.losses.Reduction.NONE)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m#sim = -cos(states[None, :, :], states[:, None, :])\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m merged_fsm \u001b[39m=\u001b[39m cosine_merging(fsm, states, states_mask)\n",
      "Cell \u001b[1;32mIn[39], line 22\u001b[0m, in \u001b[0;36mcosine_merging\u001b[1;34m(fsm, states, states_mask, threshold)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m pass_:\n\u001b[0;32m     20\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mif\u001b[39;00m(sim[i][j] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold):\n\u001b[0;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe states to merge \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m     fusionable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 0; input has only 0 dims [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "mask = [[True, True, True, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, False, False, False],\n",
    "        [True, True, True, True, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, False, False],\n",
    "        [True, True, True, True, True],\n",
    "        [True, True, True, True, False]]\n",
    "labels  = np.array([[0,1,1,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,2,2,2],\n",
    "        [0,1,1,0,2],\n",
    "        [0,1,1,0,0],\n",
    "        [0,1,0,2,2],\n",
    "        [0,1,0,1,0],\n",
    "        [0,1,0,1,2]])\n",
    "representations = np.array([[[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.1, 3.01], [2.67, 1.01], [2.67, 1.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.1, 3.01], [2.1, 3.01]],\n",
    "                   [[2.3, 4.5], [2.1, 3.01], [2.3, 4.5], [2.3, 4.5], [2.67, 1.01]]])\n",
    "idx = [[0,1,2], \n",
    "    [0,1],\n",
    "    [0,3],\n",
    "    [0,1,2,4],\n",
    "    [0,1,2,4,5],\n",
    "    [0,3,6],\n",
    "    [0,3,7,8,9],\n",
    "    [0,3,7,10]] # maps strings to states\n",
    "n_states = 11\n",
    "states = np.zeros((n_states, 2))\n",
    "states_mask = np.zeros(n_states)\n",
    "\n",
    "for i, _r in enumerate(representations):\n",
    "    #print(_r)\n",
    "    states[idx[i]] = _r[mask[i]]\n",
    "    states_mask[idx[i]] = labels[i][mask[i]]\n",
    "\n",
    "#cos = tf.keras.losses.CosineSimilarity(axis=-1,reduction=tf.keras.losses.Reduction.NONE)\n",
    "#sim = -cos(states[None, :, :], states[:, None, :])\n",
    "\n",
    "merged_fsm = cosine_merging(fsm, states, states_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'110'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_fsm.return_output('bab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb', 'abb', 'aaaa', 'baaaaab', 'abababb']\n",
    "_labels = ['11', '1', '0', '111', '0', '1111', '00', '1', '0111', '010', '10', '011', '0000', '1111110', '0110100']\n",
    "def score_whole_words(mealy, dataset, labels):\n",
    "    acc = 0\n",
    "    for word, y in zip(dataset, labels):\n",
    "        acc += (mealy.return_output(word) == y)\n",
    "    return (acc / len(dataset) * 100)\n",
    "\n",
    "_acc = score_whole_words(merged_fsm, _corpus, _labels)\n",
    "_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11, 11), dtype=float64, numpy=\n",
       "array([[1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [0.99067566, 0.99067566, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99067566, 1.        , 1.        ,\n",
       "        0.99067566],\n",
       "       [1.        , 1.        , 0.99067566, 0.99067566, 0.99067566,\n",
       "        0.99067566, 0.99067566, 1.        , 0.99067566, 0.99067566,\n",
       "        1.        ]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 1e-12 to EagerTensor of dtype int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m], [\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m]])\n\u001b[0;32m      2\u001b[0m b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m2.1\u001b[39m, \u001b[39m3.2\u001b[39m], [\u001b[39m4.8\u001b[39m, \u001b[39m5.7\u001b[39m]])\n\u001b[1;32m----> 3\u001b[0m sim \u001b[39m=\u001b[39m cos(a[\u001b[39mNone\u001b[39;49;00m, :, :], a[:, \u001b[39mNone\u001b[39;49;00m, :])\n\u001b[0;32m      4\u001b[0m sim\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py:142\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    139\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 142\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[0;32m    144\u001b[0m in_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(y_pred)\n\u001b[0;32m    145\u001b[0m out_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(losses)\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py:268\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    261\u001b[0m     y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    262\u001b[0m         y_pred, y_true\n\u001b[0;32m    263\u001b[0m     )\n\u001b[0;32m    265\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    267\u001b[0m )\n\u001b[1;32m--> 268\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Gael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py:2461\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(y_true, y_pred, axis)\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[39m@keras_export\u001b[39m(\n\u001b[0;32m   2421\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkeras.losses.cosine_similarity\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2422\u001b[0m     v1\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcosine_similarity\u001b[39m(y_true, y_pred, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   2432\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Computes the cosine similarity between labels and predictions.\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \n\u001b[0;32m   2434\u001b[0m \u001b[39m    Note that it is a number between -1 and 1. When it is a negative number\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2459\u001b[0m \u001b[39m      Cosine similarity tensor.\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2461\u001b[0m     y_true \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49ml2_normalize(y_true, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   2462\u001b[0m     y_pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39ml2_normalize(y_pred, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   2463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mtf\u001b[39m.\u001b[39mreduce_sum(y_true \u001b[39m*\u001b[39m y_pred, axis\u001b[39m=\u001b[39maxis)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert 1e-12 to EagerTensor of dtype int32"
     ]
    }
   ],
   "source": [
    "a = np.array([[2,3], [5,6]])\n",
    "b = np.array([[2.1, 3.2], [4.8, 5.7]])\n",
    "sim2 = cos(a[None, :, :], a[:, None, :])\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rer = [['a','0'],['b','1']]\n",
    "rerr = []\n",
    "sas = []\n",
    "if all(x in rer for x in rerr):\n",
    "    print(True)\n",
    "#rer = [set(x) for x in rer]\n",
    "#rerr = [set(x) for x in rerr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from mealy_machine import Mealy\n",
    "def fsm_equivalence(fsm1 : Mealy, fsm2 : Mealy):\n",
    "    if set(fsm1.inputAlphabet) != set(fsm2.inputAlphabet):\n",
    "        print('The two FSM don\\'t have the same input set' )\n",
    "        return 0\n",
    "    if set(fsm1.outputAlphabet) != set(fsm2.outputAlphabet):\n",
    "        print('The two FSM don\\'t have the same output set' )\n",
    "        return 0\n",
    "    start = (fsm1.root, fsm2.root)\n",
    "    inputAlphabet = set(fsm1.inputAlphabet + fsm2.inputAlphabet)\n",
    "    outputAlphabet = set(fsm1.outputAlphabet + fsm2.outputAlphabet)\n",
    "    nodes = [start]\n",
    "    nodes_ = deepcopy(nodes)\n",
    "    print('Starting')\n",
    "    print(nodes[0])\n",
    "    while len(nodes) != 0:\n",
    "        node = nodes[0]\n",
    "        for x in inputAlphabet:\n",
    "            output1 = fsm1.output(node[0], x)\n",
    "            output2 = fsm2.output(node[1], x)\n",
    "            #print(f'The len is {len(nodes)}')\n",
    "            #print(f'{node}   {x}   {(output1[1],output2[1])}')\n",
    "            if output1[0] != output2[0]:\n",
    "                return 0\n",
    "            \n",
    "            #print((output1[1], output2[1]))\n",
    "            node_ = (output1[1], output2[1])\n",
    "            if node_ not in nodes_:\n",
    "                nodes_.append(node_)\n",
    "                nodes.append(node_)\n",
    "        \n",
    "        nodes.pop(0)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "(0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mealy_machine import Mealy\n",
    "nodes1 = [0, 1, 2, 4]\n",
    "nodes2 = [0, 1]\n",
    "\n",
    "arcs1 = [(0,'b','1',1),\n",
    "         (1,'a','1',2),\n",
    "         (2,'a','0',4),\n",
    "         (4,'a','0',4),\n",
    "         (4,'b','0',0),\n",
    "         (1,'b','1',1),\n",
    "         (0,'a','1',2),\n",
    "         (2,'b','0',0)]\n",
    "arcs2 = [(0,'b','1',0),\n",
    "         (0,'a','1',1),\n",
    "         (1,'a','0',1),\n",
    "         (1,'b','0',0)]\n",
    "fsm1 = Mealy(0, 0, nodes1, arcs1)\n",
    "fsm2 = Mealy(1, 0, nodes2, arcs2)\n",
    "fsm_equivalence(fsm1, fsm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "rere = [5,8,9,6]\n",
    "for i in rere:\n",
    "    if i < 2:\n",
    "        break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus, labels, max_length):\n",
    "    \n",
    "    bos = ['e', 'f', 'g']  # Plausible beginning of sentence marker\n",
    "    for b in bos:\n",
    "        if b not in set(corpus):\n",
    "            break\n",
    "\n",
    "    eos = ['z', 'y', 'x'] # Plausible end of sentence marker\n",
    "    \n",
    "    for e in eos:\n",
    "        if e not in set(corpus):\n",
    "            break\n",
    "    pad_label = ['0', '1', '2', '3', '4']  \n",
    "\n",
    "    corpus_ = [b+x+e*(max_length-len(x)) for x in corpus]\n",
    "\n",
    "    for p in pad_label:\n",
    "        if p not in set(corpus):\n",
    "            break\n",
    "    labels_ = ['0'+x+p*(max_length-len(x)) for x in labels]\n",
    "    return corpus_, labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ebazzzzz', 'ebzzzzzz', 'eazzzzzz', 'ebaazzzz', 'eazzzzzz', 'ebaaazzz', 'eaazzzzz', 'ebzzzzzz', 'eabaazzz', 'eabbzzzz', 'ebbzzzzz', 'eabbzzzz', 'eaaaazzz', 'ebaaaaab', 'eabababa']\n",
      "['01100000', '01000000', '01000000', '01100000', '01000000', '01100000', '01000000', '01000000', '01010000', '01010000', '01100000', '01010000', '01000000', '01100000', '01010101']\n"
     ]
    }
   ],
   "source": [
    "corpus = ['ba', 'b', 'a', 'baa', 'a', 'baaa', 'aa', 'b', 'abaa', 'abb', 'bb', 'abb', 'aaaa', 'baaaaab', 'abababa']\n",
    "labels = ['11', '1', '1', '110', '1', '1100', '10', '1', '1010', '101', '11', '101', '1000', '1100000', '1010101']\n",
    "assert(len(corpus) == len(labels))\n",
    "max_length = len(max(corpus, key=len))\n",
    "corpus_, labels_ = preprocessing(corpus, labels, max_length)\n",
    "print(corpus_)\n",
    "print(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbaabbbabb',\n",
       " 'ba',\n",
       " 'baaaa',\n",
       " 'bbbbabbbbbb',\n",
       " 'babbbbabaaba',\n",
       " 'aabaabbbabbab',\n",
       " 'aaabab',\n",
       " 'babababaaa',\n",
       " 'babababbabbaaa',\n",
       " 'aaaabbabbbbaba',\n",
       " 'aababa',\n",
       " 'abb',\n",
       " 'b',\n",
       " 'baabaabaa',\n",
       " 'baabaabb',\n",
       " 'aaaba',\n",
       " 'ab',\n",
       " 'aababbbbbaa',\n",
       " 'abaaaababababb',\n",
       " 'aaaaabaababaaa',\n",
       " 'bbabbbbabb',\n",
       " 'abbbb',\n",
       " 'b',\n",
       " 'abbabbba',\n",
       " 'b',\n",
       " 'babbaabbbba',\n",
       " 'bababbaabbbb',\n",
       " 'abaa',\n",
       " 'abbaaabb',\n",
       " 'aabbbababb',\n",
       " 'aaabbaabbb',\n",
       " 'aabbabba',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'bbbbabababbbaa',\n",
       " 'bbabbababbabb',\n",
       " 'bbbb',\n",
       " 'abaaabbabbabb',\n",
       " 'baaabb',\n",
       " 'abab',\n",
       " 'bbbbababaaabb',\n",
       " 'abbabab',\n",
       " 'bbaababa',\n",
       " 'bbabbbab',\n",
       " 'abbbbab',\n",
       " 'abbbabaa',\n",
       " 'abababaaaaaaa',\n",
       " 'bbbbbaabaaba',\n",
       " 'abbbbaabbbab',\n",
       " 'abaaabbabbab',\n",
       " 'bbaab',\n",
       " 'baaaaa',\n",
       " 'babbababbbab',\n",
       " 'baabbb',\n",
       " 'aaaa',\n",
       " 'abbbbb',\n",
       " 'ababbbaaaabbb',\n",
       " 'aaaaaaaa',\n",
       " 'ab',\n",
       " 'bba',\n",
       " 'bbbbbaabbb',\n",
       " 'abaab',\n",
       " 'bba',\n",
       " 'babbaaaabaaaa',\n",
       " 'aaaaaabbbb',\n",
       " 'babbbbaaaaa',\n",
       " 'baa',\n",
       " 'baabbb',\n",
       " 'b',\n",
       " 'bbbbaababbaba',\n",
       " 'aaaaabbba',\n",
       " 'bbbaaaabab',\n",
       " 'abbbb',\n",
       " 'a',\n",
       " 'baaaaaaabb',\n",
       " 'aaaabbbaaaabba',\n",
       " 'aabababaaab',\n",
       " 'bababbab',\n",
       " 'babaaaa',\n",
       " 'bbabb',\n",
       " 'abbaab',\n",
       " 'bbb',\n",
       " 'babaaabbbaab',\n",
       " 'a',\n",
       " 'aaabbbaa',\n",
       " 'ababaaaabbabaa',\n",
       " 'aaaaabb',\n",
       " 'abababaab',\n",
       " 'bababbab',\n",
       " 'baaba',\n",
       " 'bbababbbbbbbba',\n",
       " 'abaaaa',\n",
       " 'abbbbb',\n",
       " 'bbabaaaababaaa',\n",
       " 'aabbbbaababa',\n",
       " 'aabaa',\n",
       " 'baabab',\n",
       " 'aaaababab',\n",
       " 'aaaaaba',\n",
       " 'aba',\n",
       " 'abbbbbbbaaab',\n",
       " 'bbabaa',\n",
       " 'babababbb',\n",
       " 'b',\n",
       " 'baaabbabb',\n",
       " 'aaabaaabaab',\n",
       " 'bbaabb',\n",
       " 'b',\n",
       " 'abaabaa',\n",
       " 'abaaa',\n",
       " 'aabbabb',\n",
       " 'bbaaba',\n",
       " 'bbbbbbab',\n",
       " 'babbb',\n",
       " 'baaababba',\n",
       " 'babaaababab',\n",
       " 'bababbabbbbaba',\n",
       " 'bbbabab',\n",
       " 'bb',\n",
       " 'baaaaabbba',\n",
       " 'abaabab',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'abbbbbaa',\n",
       " 'bbb',\n",
       " 'abbbbabbaa',\n",
       " 'bbbabbaaaa',\n",
       " 'baaaabba',\n",
       " 'abaaaaabab',\n",
       " 'abbbbababab',\n",
       " 'aaababab',\n",
       " 'aababbaa',\n",
       " 'bababbba',\n",
       " 'a',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'baaabbbababb',\n",
       " 'bbabbb',\n",
       " 'bbaababbaaa',\n",
       " 'aab',\n",
       " 'aaaaa',\n",
       " 'baa',\n",
       " 'bbb',\n",
       " 'abbbbb',\n",
       " 'aabbb',\n",
       " 'bbabaa',\n",
       " 'bbabaabbaaa',\n",
       " 'aba',\n",
       " 'aa',\n",
       " 'bababaabb',\n",
       " 'aa',\n",
       " 'bbabbbbba',\n",
       " 'b',\n",
       " 'aaababbaba',\n",
       " 'aaab',\n",
       " 'bba',\n",
       " 'aabbaaabba',\n",
       " 'aaaaab',\n",
       " 'bbabbabaaa',\n",
       " 'abbabbbbaa',\n",
       " 'aaababaaaaa',\n",
       " 'bbbbbbbbbba',\n",
       " 'abaabaaabaaa',\n",
       " 'aabb',\n",
       " 'abbbabbbbb',\n",
       " 'abbbbbbabaaba',\n",
       " 'aaaababb',\n",
       " 'aaabbbaab',\n",
       " 'abbaa',\n",
       " 'ababbbabaab',\n",
       " 'aaaabba',\n",
       " 'ab',\n",
       " 'bbaabbba',\n",
       " 'bb',\n",
       " 'bbbaaa',\n",
       " 'bbbaba',\n",
       " 'baaba',\n",
       " 'bbbaaaba',\n",
       " 'aabaaa',\n",
       " 'baabababba',\n",
       " 'aabaaa',\n",
       " 'babbb',\n",
       " 'bbabbbbbb',\n",
       " 'abbb',\n",
       " 'abababaabbba',\n",
       " 'baabbbbbaba',\n",
       " 'bbaaaabababb',\n",
       " 'aabaabaaaaa',\n",
       " 'abbba',\n",
       " 'abaabbabbabba',\n",
       " 'bbbbbaabaaa',\n",
       " 'aaaaabbaaa',\n",
       " 'bbbabba',\n",
       " 'bbabbab',\n",
       " 'bbbbbababbaa',\n",
       " 'baaa',\n",
       " 'bbaabbabaaab',\n",
       " 'bababbbaaab',\n",
       " 'b',\n",
       " 'bababbbbaabaaa',\n",
       " 'abaaabbbb',\n",
       " 'abaaababbabab',\n",
       " 'aaaaaaa',\n",
       " 'baaaaaaabbbbaa',\n",
       " 'bbaaaaa',\n",
       " 'ababaa',\n",
       " 'ba',\n",
       " 'bba',\n",
       " 'aaaabaaabaabb',\n",
       " 'aabaab',\n",
       " 'b',\n",
       " 'aba',\n",
       " 'bb',\n",
       " 'bb',\n",
       " 'aababaabbaa',\n",
       " 'babababaababa',\n",
       " 'baabab',\n",
       " 'baaaaba',\n",
       " 'aabab',\n",
       " 'baaabbbbbbba',\n",
       " 'aaaaba',\n",
       " 'aaba',\n",
       " 'aaaabb',\n",
       " 'bbabbaaa',\n",
       " 'bbbabaababb',\n",
       " 'bbbbaaabaaab',\n",
       " 'babbbbbb',\n",
       " 'abbb',\n",
       " 'baba',\n",
       " 'abaaab',\n",
       " 'aaaaab',\n",
       " 'aabbb',\n",
       " 'abaab',\n",
       " 'aabaaa',\n",
       " 'bbaab',\n",
       " 'ababaaababa',\n",
       " 'aaaabaab',\n",
       " 'babbaa',\n",
       " 'aba',\n",
       " 'a',\n",
       " 'aabaabbb',\n",
       " 'bba',\n",
       " 'aaaabab',\n",
       " 'bbbaaabaabab',\n",
       " 'babbbaaa',\n",
       " 'aaa',\n",
       " 'bababaaabba',\n",
       " 'aaabbababbbba',\n",
       " 'bbaababaabbabb',\n",
       " 'abbbab',\n",
       " 'abbbbbbaabbbb',\n",
       " 'bb',\n",
       " 'baaabaaaabbab',\n",
       " 'ababbba',\n",
       " 'ba',\n",
       " 'b',\n",
       " 'aaabbaa',\n",
       " 'aaaaaaba',\n",
       " 'aabb',\n",
       " 'abbbbbbbbbab',\n",
       " 'baaaaab',\n",
       " 'babbabbbaaa',\n",
       " 'babbaaab',\n",
       " 'babbaababb',\n",
       " 'abaabbabbaaaaa',\n",
       " 'aa',\n",
       " 'abbbaabbab',\n",
       " 'aab',\n",
       " 'bbbbbaaaaaa',\n",
       " 'abaaabbababb',\n",
       " 'aba',\n",
       " 'bab',\n",
       " 'aabbabaabaaaa',\n",
       " 'babbbbb',\n",
       " 'aaaabaabaaaa',\n",
       " 'ababb',\n",
       " 'abaab',\n",
       " 'b',\n",
       " 'bbaabbab',\n",
       " 'abbbbbbab',\n",
       " 'aaabbaaaaa',\n",
       " 'baaabb',\n",
       " 'babb',\n",
       " 'aabbb',\n",
       " 'ba',\n",
       " 'abbabaaabb',\n",
       " 'bababaababbbab',\n",
       " 'ababb',\n",
       " 'bbabaaaaabaaab',\n",
       " 'abbabbb',\n",
       " 'baabaa',\n",
       " 'bbbbbaabbaabb',\n",
       " 'baabbbababb',\n",
       " 'baba',\n",
       " 'babaababbaabbb',\n",
       " 'bb',\n",
       " 'babaababab',\n",
       " 'ababaa',\n",
       " 'aabaabbba',\n",
       " 'aaabaaaabbbbbb',\n",
       " 'aaaa',\n",
       " 'bababbbbbb',\n",
       " 'bbaaaaaa',\n",
       " 'abababbabbaab',\n",
       " 'abaab',\n",
       " 'aaaaaaababb',\n",
       " 'bba',\n",
       " 'bbabbababaaab',\n",
       " 'bbaa',\n",
       " 'baaabbabbabaa',\n",
       " 'aaab',\n",
       " 'a',\n",
       " 'bbbabbaaababb',\n",
       " 'aababaaaaab',\n",
       " 'aab',\n",
       " 'babaa',\n",
       " 'bbaabbabbbb',\n",
       " 'babb',\n",
       " 'bbbb',\n",
       " 'bbbaabaaa',\n",
       " 'aaaabbb',\n",
       " 'baabaabaaabba',\n",
       " 'abbabbbaaaba',\n",
       " 'abbababababb',\n",
       " 'bbbbbaabaabbaa',\n",
       " 'baa',\n",
       " 'ba',\n",
       " 'ababaaa',\n",
       " 'aabb',\n",
       " 'bbabbbabbbbbb',\n",
       " 'ababbabababbba',\n",
       " 'baaababbbba',\n",
       " 'bbabababb',\n",
       " 'baaaabbabababb',\n",
       " 'baaaabbb',\n",
       " 'a',\n",
       " 'baa',\n",
       " 'abbbaabbabb',\n",
       " 'bb',\n",
       " 'a',\n",
       " 'babaabbb',\n",
       " 'bbb',\n",
       " 'babb',\n",
       " 'a',\n",
       " 'ababb',\n",
       " 'bba',\n",
       " 'bbbbbaabbabba',\n",
       " 'abbbbbbbbab',\n",
       " 'bbbabbbbb',\n",
       " 'ba',\n",
       " 'aa',\n",
       " 'aabaab',\n",
       " 'bbb',\n",
       " 'abababaabbabbb',\n",
       " 'bbbbbbaaaaaba',\n",
       " 'aabbbbaaa',\n",
       " 'babaababbbbb',\n",
       " 'abaaab',\n",
       " 'baaab',\n",
       " 'babbbbbabbaaab',\n",
       " 'bbaba',\n",
       " 'aabaaaaa',\n",
       " 'bbbbaaaabbbab',\n",
       " 'abababbaabb',\n",
       " 'baaaaabbbab',\n",
       " 'abbaa',\n",
       " 'abbbbabbaaa',\n",
       " 'aab',\n",
       " 'aa',\n",
       " 'abbaaabbaaa',\n",
       " 'bbba',\n",
       " 'baaaaabbaaa',\n",
       " 'a',\n",
       " 'aabba',\n",
       " 'baa',\n",
       " 'bbab',\n",
       " 'aaab',\n",
       " 'babaaaababbb',\n",
       " 'aab',\n",
       " 'aababbabaaab',\n",
       " 'aab',\n",
       " 'aaaaba',\n",
       " 'aabaaabb',\n",
       " 'baaaaaabbab',\n",
       " 'aab',\n",
       " 'abbbbb',\n",
       " 'abbbbbababbbab',\n",
       " 'aaaaa',\n",
       " 'baa',\n",
       " 'abbabbaaababa',\n",
       " 'aa',\n",
       " 'aabbb',\n",
       " 'ba',\n",
       " 'abbbab',\n",
       " 'bbabbbbbaab',\n",
       " 'ababbaababbbb',\n",
       " 'b',\n",
       " 'bbbbaaabababa',\n",
       " 'bbaba',\n",
       " 'bbabbaab',\n",
       " 'aababaaabbbaa',\n",
       " 'a',\n",
       " 'aababbba',\n",
       " 'baaaa',\n",
       " 'aaabaaabb',\n",
       " 'abb',\n",
       " 'ababb',\n",
       " 'bbbbaaab',\n",
       " 'abbbbbaba',\n",
       " 'aaabbbbab',\n",
       " 'b',\n",
       " 'abbbbbabbbabbb',\n",
       " 'abbbaaaab',\n",
       " 'aababaabbbb',\n",
       " 'bbaaabaaab',\n",
       " 'baaaabaabababa',\n",
       " 'bba',\n",
       " 'b',\n",
       " 'aabbbbaabbab',\n",
       " 'aababaaa',\n",
       " 'aabbaba',\n",
       " 'babbababbbaabb',\n",
       " 'bbaaaab',\n",
       " 'baabab',\n",
       " 'aabbababbaabaa',\n",
       " 'abba',\n",
       " 'baaab',\n",
       " 'aaba',\n",
       " 'baaa',\n",
       " 'a',\n",
       " 'babaaaabaaa',\n",
       " 'b',\n",
       " 'abbaaa',\n",
       " 'aababbaabb',\n",
       " 'aaaaaaabbbab',\n",
       " 'abaaaa',\n",
       " 'aaab',\n",
       " 'aaa',\n",
       " 'abbaaaa',\n",
       " 'aabaaab',\n",
       " 'aaabbaaabab',\n",
       " 'bab',\n",
       " 'bbbabbaaaabaa',\n",
       " 'bbba',\n",
       " 'aba',\n",
       " 'abab',\n",
       " 'baababbbabbb',\n",
       " 'aabbaabb',\n",
       " 'bbbaaaaba',\n",
       " 'bbb',\n",
       " 'aba',\n",
       " 'bbbbbabb',\n",
       " 'babbbbbab',\n",
       " 'aaaababaaa',\n",
       " 'bbb',\n",
       " 'bbbbbbbabab',\n",
       " 'bababaaabba',\n",
       " 'babbbbabaaba',\n",
       " 'babbbbbbbabaa',\n",
       " 'baaabbbbbb',\n",
       " 'aaaabbaaababaa',\n",
       " 'b',\n",
       " 'babbbbabb',\n",
       " 'abbbaba',\n",
       " 'aaabaaa',\n",
       " 'aabaaaaaababb',\n",
       " 'aabbbbbbaa',\n",
       " 'a',\n",
       " 'bb',\n",
       " 'babbbbbababb',\n",
       " 'ab',\n",
       " 'bb',\n",
       " 'bbabbbaa',\n",
       " 'bbbaaaaabb',\n",
       " 'baabbabaab',\n",
       " 'abaa',\n",
       " 'aabbb',\n",
       " 'aabab',\n",
       " 'bbabbbba',\n",
       " 'aabaaab',\n",
       " 'aaaabbaabbb',\n",
       " 'baabbaaabaaab',\n",
       " 'aabaababbbb',\n",
       " 'abbabbbbababa',\n",
       " 'baa',\n",
       " 'bababbbbbbbaab',\n",
       " 'bbabbaaaaba',\n",
       " 'bbaaaabab',\n",
       " 'bbbbabbbab',\n",
       " 'bbbbbabb',\n",
       " 'baa',\n",
       " 'aabbbaaaabbab',\n",
       " 'aabaabbbaabaa',\n",
       " 'bbab',\n",
       " 'aaabbabaababa',\n",
       " 'bbbbabbbbbabba',\n",
       " 'bbbaabbbbab',\n",
       " 'abbaaba',\n",
       " 'b',\n",
       " 'abaababbababab',\n",
       " 'a',\n",
       " 'bbbbaa',\n",
       " 'ababaaaabaaaa',\n",
       " 'ababbba',\n",
       " 'bbbabbb',\n",
       " 'abaabbbbbbbab',\n",
       " 'abaaaab',\n",
       " 'a',\n",
       " 'baba',\n",
       " 'abba',\n",
       " 'babb',\n",
       " 'bab',\n",
       " 'baaababaaaa',\n",
       " 'abbaababb',\n",
       " 'aaabbabbabb',\n",
       " 'aabbabbab',\n",
       " 'aaaaabaababbba',\n",
       " 'b',\n",
       " 'aabb',\n",
       " 'abaaaab',\n",
       " 'b',\n",
       " 'abbbbb',\n",
       " 'aaaabbaaa',\n",
       " 'abaaaabbaab',\n",
       " 'bbbabbabaab',\n",
       " 'abaaabbbbb',\n",
       " 'baaaab',\n",
       " 'aab',\n",
       " 'bbbbaaaabaabb',\n",
       " 'b',\n",
       " 'bbabbaabbaaa',\n",
       " 'aaababaaaabaab',\n",
       " 'abba',\n",
       " 'ababbabaaabbab',\n",
       " 'abaabaaaaaaaa',\n",
       " 'b',\n",
       " 'abaaaaa',\n",
       " 'baaabbababbabb',\n",
       " 'aba',\n",
       " 'bbaabbbba',\n",
       " 'babaaabaabab',\n",
       " 'bababb',\n",
       " 'bbaaaa',\n",
       " 'b',\n",
       " 'aababbaaabaa',\n",
       " 'bbbaaaa',\n",
       " 'bb',\n",
       " 'abbaaba',\n",
       " 'bbbbabaabaa',\n",
       " 'aabbababba',\n",
       " 'abbba',\n",
       " 'bab',\n",
       " 'abaaaaaaabb',\n",
       " 'aaaaabb',\n",
       " 'abaaabbaaaaa',\n",
       " 'aabaabbabbbba',\n",
       " 'babbaabaab',\n",
       " 'babb',\n",
       " 'aaba',\n",
       " 'baaababbbaab',\n",
       " 'abbbaabaaaabba',\n",
       " 'abbaaabbaaaaa',\n",
       " 'aaaabba',\n",
       " 'abbaaaa',\n",
       " 'babbaabaaa',\n",
       " 'abbababbbbb',\n",
       " 'abbbabbb',\n",
       " 'bbaa',\n",
       " 'b',\n",
       " 'abb',\n",
       " 'bababaabb',\n",
       " 'bbbaab',\n",
       " 'a',\n",
       " 'aaaaabbbabb',\n",
       " 'baabbaba',\n",
       " 'abbaba',\n",
       " 'aaaaab',\n",
       " 'bababbbabaab',\n",
       " 'bbbaaaabbbbbb',\n",
       " 'bba',\n",
       " 'bbaa',\n",
       " 'baabaabababb',\n",
       " 'aabababaaabb',\n",
       " 'bbaaaabaab',\n",
       " 'a',\n",
       " 'bbbbbaabbbb',\n",
       " 'ababab',\n",
       " 'aab',\n",
       " 'bbbbaaabbaa',\n",
       " 'bbbbbb',\n",
       " 'baba',\n",
       " 'baaa',\n",
       " 'baabaabbabbab',\n",
       " 'baabb',\n",
       " 'aababaaaaabbba',\n",
       " 'bbaabaabbbabba',\n",
       " 'a',\n",
       " 'bbaabbbbabbb',\n",
       " 'babbbbbbaa',\n",
       " 'aaaababbbbbba',\n",
       " 'bbabbaabaaaabb',\n",
       " 'aa',\n",
       " 'bbbaabaaa',\n",
       " 'bbaaabaabaaa',\n",
       " 'aabbaaabaab',\n",
       " 'abbaabbb',\n",
       " 'aaab',\n",
       " 'abab',\n",
       " 'baababbabbaab',\n",
       " 'abbaabb',\n",
       " 'baabbbaab',\n",
       " 'bbabbbb',\n",
       " 'baaabbaaabbbbb',\n",
       " 'b',\n",
       " 'aabb',\n",
       " 'babbabbbabbbbb',\n",
       " 'aabaaa',\n",
       " 'aaabbbbabbbba',\n",
       " 'babbabab',\n",
       " 'abbbbbaabababa',\n",
       " 'ab',\n",
       " 'baabbbbbbba',\n",
       " 'bbbbaaababbb',\n",
       " 'b',\n",
       " 'bbabbab',\n",
       " 'babaaabbbaaab',\n",
       " 'aabbaaaaabaa',\n",
       " 'bbaaa',\n",
       " 'aba',\n",
       " 'ba',\n",
       " 'aaabaaabbb',\n",
       " 'aabbabbb',\n",
       " 'abba',\n",
       " 'bab',\n",
       " 'baabbbba',\n",
       " 'abababa',\n",
       " 'abbabbaa',\n",
       " 'bbbbaabab',\n",
       " 'abaaaaabaaab',\n",
       " 'baa',\n",
       " 'aaaabaa',\n",
       " 'ababaaabbabba',\n",
       " 'aababbb',\n",
       " 'bababbbbbbbbab',\n",
       " 'babbaabbaaaa',\n",
       " 'baabbbabbb',\n",
       " 'bbabaabababbba',\n",
       " 'aababbbbaa',\n",
       " 'babbbaaaabab',\n",
       " 'abbbaababa',\n",
       " 'aaaabaabb',\n",
       " 'abbbabab',\n",
       " 'aba',\n",
       " 'abaaba',\n",
       " 'bbaaababaaaaba',\n",
       " 'baaaaa',\n",
       " 'aaabbabaab',\n",
       " 'ba',\n",
       " 'babbbbbba',\n",
       " 'babaabaaba',\n",
       " 'b',\n",
       " 'abbaaaaaab',\n",
       " 'b',\n",
       " 'a',\n",
       " 'bb',\n",
       " 'abbabb',\n",
       " 'ab',\n",
       " 'aaababb',\n",
       " 'aaab',\n",
       " 'a',\n",
       " 'aaaaab',\n",
       " 'bbba',\n",
       " 'b',\n",
       " 'b',\n",
       " 'baa',\n",
       " 'bbaabbbbbaaaba',\n",
       " 'babb',\n",
       " 'aabbaa',\n",
       " 'abababaaab',\n",
       " 'aaaababbabbb',\n",
       " 'aaaaaaabbb',\n",
       " 'abaabaaaab',\n",
       " 'a',\n",
       " 'aaaaabaaabaabb',\n",
       " 'baaabaaaba',\n",
       " 'abbbaaabaaa',\n",
       " 'abababba',\n",
       " 'baabaaabbb',\n",
       " 'abbbbba',\n",
       " 'babbbaaaa',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'bbbabb',\n",
       " 'abbaabbbaaaa',\n",
       " 'aabb',\n",
       " 'aa',\n",
       " 'babaa',\n",
       " 'baaaabbbbaaaba',\n",
       " 'bababbaaaa',\n",
       " 'abbabb',\n",
       " 'aabaabbba',\n",
       " 'baabaaaabbbbab',\n",
       " 'aaababa',\n",
       " 'abbabb',\n",
       " 'bbbbbb',\n",
       " 'babbbbaaa',\n",
       " 'aaab',\n",
       " 'abaaabb',\n",
       " 'aa',\n",
       " 'abbaa',\n",
       " 'b',\n",
       " 'abaabbbba',\n",
       " 'bababbbbb',\n",
       " 'baabbaabaaa',\n",
       " 'baaaabaabb',\n",
       " 'aabbbabbb',\n",
       " 'baa',\n",
       " 'ababababababba',\n",
       " 'babbaababaabaa',\n",
       " 'aba',\n",
       " 'bbaaaabbba',\n",
       " 'bab',\n",
       " 'abbbaabbbaba',\n",
       " 'baaababababbbb',\n",
       " 'b',\n",
       " 'aabbbbbaa',\n",
       " 'bba',\n",
       " 'ba',\n",
       " 'aaab',\n",
       " 'aabbbbbabbbb',\n",
       " 'ba',\n",
       " 'ab',\n",
       " 'bbaab',\n",
       " 'ab',\n",
       " 'baabbabaabbb',\n",
       " 'baabbaaabb',\n",
       " 'bbbabaaabbbabb',\n",
       " 'bbabb',\n",
       " 'aaa',\n",
       " 'a',\n",
       " 'aaaaaaaaabb',\n",
       " 'bbbabbbba',\n",
       " 'a',\n",
       " 'bbaaaa',\n",
       " 'ba',\n",
       " 'bb',\n",
       " 'abbaaa',\n",
       " 'a',\n",
       " 'abbbb',\n",
       " 'bb',\n",
       " 'bbaaa',\n",
       " 'abbbab',\n",
       " 'bbabbbbaabbaab',\n",
       " 'abbbbaabb',\n",
       " 'b',\n",
       " 'abbaaab',\n",
       " 'bbaa',\n",
       " 'ababbaba',\n",
       " 'bbaabb',\n",
       " 'aaaba',\n",
       " 'aaaabaaa',\n",
       " 'abbababaa',\n",
       " 'bbbbab',\n",
       " 'bbabbabbaab',\n",
       " 'abbaabbaa',\n",
       " 'abb',\n",
       " 'bbbaaaaaababaa',\n",
       " 'a',\n",
       " 'bbaba',\n",
       " 'bbabbbbbabaaa',\n",
       " 'bbabaabbbabaa',\n",
       " 'aaa',\n",
       " 'a',\n",
       " 'abbaaabbbbaaa',\n",
       " 'abbaaababab',\n",
       " 'babbaaabbba',\n",
       " 'bbbabaaaaa',\n",
       " 'babba',\n",
       " 'babbbaab',\n",
       " 'bbaabab',\n",
       " 'baaaabbabba',\n",
       " 'bbaaabbaabb',\n",
       " 'aababbaa',\n",
       " 'abbb',\n",
       " 'bbbbaba',\n",
       " 'abaaaabaabbbaa',\n",
       " 'bbbbbbaaaa',\n",
       " 'b',\n",
       " 'aabaaabbabb',\n",
       " 'aaaa',\n",
       " 'aaababbbaabaa',\n",
       " 'b',\n",
       " 'baaa',\n",
       " 'babaabbaab',\n",
       " 'abbabaaaabaaa',\n",
       " 'aaba',\n",
       " 'bbaabbabbaba',\n",
       " 'aba',\n",
       " 'bababbbbbabbaa',\n",
       " 'babbbabb',\n",
       " 'abbabba',\n",
       " 'aaaa',\n",
       " 'baaabbaa',\n",
       " 'babbbbaabbbaa',\n",
       " 'aaabbababbbbaa',\n",
       " 'aabbaaaaaba',\n",
       " 'baaaaaba',\n",
       " 'ababbb',\n",
       " 'aabababbaabaa',\n",
       " 'aaaabbbabbbaa',\n",
       " 'abaaaabaab',\n",
       " 'aaabbbab',\n",
       " 'baaaabbaabbaa',\n",
       " 'abbaaaa',\n",
       " 'baaa',\n",
       " 'ababbbbbabaaba',\n",
       " 'baaabb',\n",
       " 'abaaaa',\n",
       " 'bbbaba',\n",
       " 'abaabbabbaab',\n",
       " 'b',\n",
       " 'bbbbbaaba',\n",
       " 'abaaaaababb',\n",
       " 'aa',\n",
       " 'abbbbbbbaaab',\n",
       " 'a',\n",
       " 'babb',\n",
       " 'bbaababbbabba',\n",
       " 'baabbbbbababa',\n",
       " 'aaaaaababaaa',\n",
       " 'a',\n",
       " 'bbbbbbaab',\n",
       " 'a',\n",
       " 'bb',\n",
       " 'bbbbbbababaaa',\n",
       " 'baabbaaaabbb',\n",
       " 'baaaaaababbabb',\n",
       " 'bbabbabb',\n",
       " 'abbbabaaaabab',\n",
       " 'baab',\n",
       " 'abbbababaabab',\n",
       " 'bbabbbaaaaa',\n",
       " 'abbababaaaba',\n",
       " 'aab',\n",
       " 'babababba',\n",
       " 'babaa',\n",
       " 'aababaaaabbba',\n",
       " 'abaab',\n",
       " 'aab',\n",
       " 'abab',\n",
       " 'aababbb',\n",
       " 'bbaaaba',\n",
       " 'a',\n",
       " 'abaaabbb',\n",
       " 'bbbbabba',\n",
       " 'a',\n",
       " 'bbaa',\n",
       " 'baabaaabaaab',\n",
       " 'abababbaabbaaa',\n",
       " 'b',\n",
       " 'aab',\n",
       " 'aababababaab',\n",
       " 'bababbaabababb',\n",
       " 'ababa',\n",
       " 'bba',\n",
       " 'aabbaaabab',\n",
       " 'abbaaa',\n",
       " 'baaabbaabbaa',\n",
       " 'bbbb',\n",
       " 'bababba',\n",
       " 'baababbaabbbbb',\n",
       " 'bbbbbba',\n",
       " 'babaaaba',\n",
       " 'babbbbababa',\n",
       " 'abbbabbbbaab',\n",
       " 'aa',\n",
       " 'aababbbababaaa',\n",
       " 'abbab',\n",
       " 'bbaabbbbbbab',\n",
       " 'aabaaaaabbbabb',\n",
       " 'aabbbbaaaa',\n",
       " 'ab',\n",
       " 'bababbbbbba',\n",
       " 'babaaababb',\n",
       " 'ababbabaaaaba',\n",
       " 'bbbbbababaaabb',\n",
       " 'ababbbabaa',\n",
       " 'aab',\n",
       " 'babbb',\n",
       " 'bbabbbb',\n",
       " 'ab',\n",
       " 'aaaab',\n",
       " 'bbbaaaab',\n",
       " 'bbbbaaaa',\n",
       " 'a',\n",
       " 'bbaaa',\n",
       " 'babbbababb',\n",
       " 'abb',\n",
       " 'abaa',\n",
       " 'aab',\n",
       " 'ba',\n",
       " 'bababbbbbbbbb',\n",
       " 'babbbbaabbb',\n",
       " 'babbaaabab',\n",
       " 'aabbababa',\n",
       " 'aabababbbaba',\n",
       " 'bbbbbba',\n",
       " 'abbbbaaaababbb',\n",
       " 'aaa',\n",
       " 'abbbabaab',\n",
       " 'bbbabbaabbaabb',\n",
       " 'bbaaaaa',\n",
       " 'aaa',\n",
       " 'abbbabaaaab',\n",
       " 'ab',\n",
       " 'bbbb',\n",
       " 'baaa',\n",
       " 'aaababbaaba',\n",
       " 'abaaa',\n",
       " 'bbbbbbbaaaa',\n",
       " 'bbbaba',\n",
       " 'bba',\n",
       " 'ababaabbabaa',\n",
       " 'bbbbbabb',\n",
       " 'bbabbaabaaabb',\n",
       " 'aabbbbbbbbbab',\n",
       " 'baabba',\n",
       " 'abbbaaaa',\n",
       " 'abaabbbaaa',\n",
       " 'b',\n",
       " 'abbba',\n",
       " 'aabaabaaaa',\n",
       " 'aa',\n",
       " 'bbbaaab',\n",
       " 'abaabaaaab',\n",
       " 'baabbbbabaaaba',\n",
       " 'baaaabbbbabbaa',\n",
       " 'baa',\n",
       " 'a',\n",
       " 'bbaaaabbab',\n",
       " 'aaaaaaaabaa',\n",
       " 'abaaab',\n",
       " 'bbbaaa',\n",
       " 'b',\n",
       " 'bba',\n",
       " 'baabbabbabbab',\n",
       " 'bbbaaabbb',\n",
       " 'abba',\n",
       " 'aabbaaaabba',\n",
       " 'bbaaaaba',\n",
       " 'ababbb',\n",
       " 'ababbbaaaaab',\n",
       " 'abaaababbabb',\n",
       " 'bbabaaab',\n",
       " 'abbbbbbabbbba',\n",
       " 'abbaabbbbabaa',\n",
       " 'b',\n",
       " 'aabbaaa',\n",
       " 'a',\n",
       " 'baabbbbb',\n",
       " 'b',\n",
       " 'bbabaaaabab',\n",
       " 'b',\n",
       " 'babababbbbb',\n",
       " 'a',\n",
       " 'babaa',\n",
       " 'bbbbbabaabbb',\n",
       " 'baaabbaa',\n",
       " 'bbaab',\n",
       " 'baabbb',\n",
       " 'ba',\n",
       " 'aaabaab',\n",
       " 'abaaaabba',\n",
       " 'aabbaaabaabbb',\n",
       " 'bbaabbabbabbaa',\n",
       " 'bbaabbbbbb',\n",
       " 'bb',\n",
       " 'baaababbaaba',\n",
       " 'abbababaabbbab',\n",
       " 'babbaa',\n",
       " 'bababbbaaaa',\n",
       " 'aababbbbb',\n",
       " 'baaaaaa',\n",
       " 'aaabbab',\n",
       " 'aabbbbabaaaab',\n",
       " 'ababbbaaabbaa',\n",
       " 'abbb',\n",
       " 'bbababbbaaaa',\n",
       " 'bbbbbba',\n",
       " 'baabbab',\n",
       " 'bbbbbbbb',\n",
       " 'baabababbaaa',\n",
       " 'abbba',\n",
       " 'aaba',\n",
       " 'bbbababbbbba',\n",
       " 'aaa',\n",
       " 'baaaabbbbabbba',\n",
       " 'baa',\n",
       " 'baaababaabaab',\n",
       " 'aba',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_data\n",
    "corpus, labels = get_data('dataset0.txt')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidian(h1, h2):\n",
    "    assert len(h1) == len(h2)\n",
    "    distance = 0\n",
    "    for i in range(len(h1)):\n",
    "        distance += (h1[i] - h2[i])**2\n",
    "    distance = distance**(1/2)\n",
    "    return distance\n",
    "\n",
    "euclidian([1,0], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
